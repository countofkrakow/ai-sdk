/****************************************************************************
*   Generated by ACUITY 6.30.22
*   Match ovxlib 1.1.53
*
*   Neural Network appliction network definition source file
****************************************************************************/
/*-------------------------------------------
                   Includes
 -------------------------------------------*/
#include <stdio.h>
#include <stdlib.h>

#include "vsi_nn_pub.h"

#include "vnn_global.h"
#include "vnn_yolov5ssimuint8.h"

/*-------------------------------------------
                   Macros
 -------------------------------------------*/

#define NEW_VXNODE(_node, _type, _in, _out, _uid) do {\
        _node = vsi_nn_AddNode( graph, _type, _in, _out, NULL );\
        if( NULL == _node ) {\
            goto error;\
        }\
        _node->uid = (uint32_t)_uid;\
    } while(0)

#define NEW_VIRTUAL_TENSOR(_id, _attr, _dtype) do {\
        memset( _attr.size, 0, VSI_NN_MAX_DIM_NUM * sizeof(vsi_size_t));\
        _attr.dim_num = VSI_NN_DIM_AUTO;\
        _attr.vtl = !VNN_APP_DEBUG;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set const tensor dims out of this macro.
#define NEW_CONST_TENSOR(_id, _attr, _dtype, _ofst, _size) do {\
        data = load_data( fp, _ofst, _size  );\
        if( NULL == data ) {\
            goto error;\
        }\
        _attr.vtl = FALSE;\
        _attr.is_const = TRUE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, data );\
        free( data );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        if ( enable_from_handle )\
        {\
            _id = vsi_nn_AddTensorFromHandle( graph, VSI_NN_TENSOR_ID_AUTO,\
                    & _attr, NULL );\
        }\
        else\
        {\
            _id = vsi_nn_AddTensor( graph, VSI_NN_TENSOR_ID_AUTO,\
                    & _attr, NULL );\
        }\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

// Set generic tensor dims out of this macro.
#define NEW_NORM_TENSOR_FROM_HANDLE(_id, _attr, _dtype) do {\
        _attr.vtl = FALSE;\
        _attr.is_const = FALSE;\
        _attr.dtype.vx_type = _dtype;\
        _id = vsi_nn_AddTensorFromHandle( graph, VSI_NN_TENSOR_ID_AUTO,\
                & _attr, NULL );\
        if( VSI_NN_TENSOR_ID_NA == _id ) {\
            goto error;\
        }\
    } while(0)

#define NET_NODE_NUM            (148)
#define NET_NORM_TENSOR_NUM     (4)
#define NET_CONST_TENSOR_NUM    (120)
#define NET_VIRTUAL_TENSOR_NUM  (148)
#define NET_TOTAL_TENSOR_NUM    (NET_NORM_TENSOR_NUM + NET_CONST_TENSOR_NUM + NET_VIRTUAL_TENSOR_NUM)

/*-------------------------------------------
               Local Variables
 -------------------------------------------*/

/*-------------------------------------------
                  Functions
 -------------------------------------------*/
static uint8_t* load_data
    (
    FILE  * fp,
    size_t  ofst,
    size_t  sz
    )
{
    uint8_t* data;
    ssize_t ret;
    size_t size;
    data = NULL;
    if( NULL == fp )
    {
        return NULL;
    }

    ret = VSI_FSEEK(fp, ofst, SEEK_SET);
    if (ret != 0)
    {
        VSILOGE("blob seek failure.");
        return NULL;
    }

    data = (uint8_t*)malloc(sz);
    if (data == NULL)
    {
        VSILOGE("buffer malloc failure.");
        return NULL;
    }
    size = fread(data, 1, sz, fp);
    if (size != sz || size == 0)
    {
        free(data);
        data = NULL;
        VSILOGE("Read file to buffer failed.");
    }
    return data;
} /* load_data() */

vsi_nn_graph_t * vnn_CreateYolov5sSimUint8
    (
    const char * data_file_name,
    vsi_nn_context_t in_ctx,
    const vsi_nn_preprocess_map_element_t * pre_process_map,
    uint32_t pre_process_map_count,
    const vsi_nn_postprocess_map_element_t * post_process_map,
    uint32_t post_process_map_count
    )
{
    uint32_t                _infinity = VSI_NN_FLOAT32_INF;
    vsi_status              status;
    vsi_bool                release_ctx;
    vsi_nn_context_t        ctx;
    vsi_nn_graph_t *        graph;
    vsi_nn_node_t *         node[NET_NODE_NUM];
    vsi_nn_tensor_id_t      norm_tensor[NET_NORM_TENSOR_NUM];
    vsi_nn_tensor_id_t      const_tensor[NET_CONST_TENSOR_NUM];
    vsi_nn_tensor_attr_t    attr;
    FILE *                  fp;
    uint8_t *               data;
    uint32_t                i = 0;
    char *                  use_img_process_s;
    char *                  use_from_handle = NULL;
    int32_t                 enable_pre_post_process = 0;
    int32_t                 enable_from_handle = 0;
    vsi_bool                sort = FALSE;
    vsi_bool                inference_with_nbg = FALSE;
    char*                   pos = NULL;

    uint32_t   perm_1[] = { 2, 0, 1, 3, 4 };
    uint32_t   perm_2[] = { 2, 0, 1, 3, 4 };
    uint32_t   perm_3[] = { 2, 0, 1, 3, 4 };
    vsi_size_t shape_1[] = { 80, 80, 85, 3, 1 };
    vsi_size_t shape_2[] = { 40, 40, 85, 3, 1 };
    vsi_size_t shape_3[] = { 20, 20, 85, 3, 1 };




    (void)(_infinity);
    ctx = NULL;
    graph = NULL;
    status = VSI_FAILURE;
    memset( &attr, 0, sizeof( attr ) );
    memset( &node, 0, sizeof( vsi_nn_node_t * ) * NET_NODE_NUM );

    fp = fopen( data_file_name, "rb" );
    if( NULL == fp )
    {
        VSILOGE( "Open file %s failed.", data_file_name );
        goto error;
    }

    pos = strstr(data_file_name, ".nb");
    if( pos && strcmp(pos, ".nb") == 0 )
    {
        inference_with_nbg = TRUE;
    }

    if( NULL == in_ctx )
    {
        ctx = vsi_nn_CreateContext();
    }
    else
    {
        ctx = in_ctx;
    }

    use_img_process_s = getenv( "VSI_USE_IMAGE_PROCESS" );
    if( use_img_process_s )
    {
        enable_pre_post_process = atoi(use_img_process_s);
    }
    use_from_handle = getenv( "VSI_USE_FROM_HANDLE" );
    if ( use_from_handle )
    {
        enable_from_handle = atoi(use_from_handle);
    }

    graph = vsi_nn_CreateGraph( ctx, NET_TOTAL_TENSOR_NUM, NET_NODE_NUM );
    if( NULL == graph )
    {
        VSILOGE( "Create graph fail." );
        goto error;
    }
    vsi_nn_SetGraphVersion( graph, VNN_VERSION_MAJOR, VNN_VERSION_MINOR, VNN_VERSION_PATCH );
    vsi_nn_SetGraphInputs( graph, NULL, 1 );
    vsi_nn_SetGraphOutputs( graph, NULL, 3 );
    vsi_nn_SetGraphFastMode(graph,FALSE);

/*-----------------------------------------
  Register client ops
 -----------------------------------------*/


/*-----------------------------------------
  Node definitions
 -----------------------------------------*/
    if( !inference_with_nbg )
    {

    /*-----------------------------------------
      lid       - 122_193
      var       - node[0]
      name      - 122
      operation - convolution
      input     - [640, 640, 3, 1]
      filter    - [6, 6, 3, 32]
      output    - [320, 320, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[0], VSI_NN_OP_CONV2D, 3, 1, 193);
    node[0]->nn_param.conv2d.ksize[0] = 6;
    node[0]->nn_param.conv2d.ksize[1] = 6;
    node[0]->nn_param.conv2d.weights = 32;
    node[0]->nn_param.conv2d.stride[0] = 2;
    node[0]->nn_param.conv2d.stride[1] = 2;
    node[0]->nn_param.conv2d.pad[0] = 2;
    node[0]->nn_param.conv2d.pad[1] = 2;
    node[0]->nn_param.conv2d.pad[2] = 2;
    node[0]->nn_param.conv2d.pad[3] = 2;
    node[0]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[0]->nn_param.conv2d.group = 1;
    node[0]->nn_param.conv2d.dilation[0] = 1;
    node[0]->nn_param.conv2d.dilation[1] = 1;
    node[0]->nn_param.conv2d.multiplier = 0;
    node[0]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[0]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[0]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 123_194_124_178
      var       - node[1]
      name      - swish
      operation - swish
      input     - [320, 320, 32, 1]
      output    - [320, 320, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[1], VSI_NN_OP_SWISH, 1, 1, 178);
    node[1]->nn_param.swish.type = VSI_NN_SWISH;
    node[1]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 125_177
      var       - node[2]
      name      - 125
      operation - convolution
      input     - [320, 320, 32, 1]
      filter    - [3, 3, 32, 64]
      output    - [160, 160, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[2], VSI_NN_OP_CONV2D, 3, 1, 177);
    node[2]->nn_param.conv2d.ksize[0] = 3;
    node[2]->nn_param.conv2d.ksize[1] = 3;
    node[2]->nn_param.conv2d.weights = 64;
    node[2]->nn_param.conv2d.stride[0] = 2;
    node[2]->nn_param.conv2d.stride[1] = 2;
    node[2]->nn_param.conv2d.pad[0] = 1;
    node[2]->nn_param.conv2d.pad[1] = 1;
    node[2]->nn_param.conv2d.pad[2] = 1;
    node[2]->nn_param.conv2d.pad[3] = 1;
    node[2]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[2]->nn_param.conv2d.group = 1;
    node[2]->nn_param.conv2d.dilation[0] = 1;
    node[2]->nn_param.conv2d.dilation[1] = 1;
    node[2]->nn_param.conv2d.multiplier = 0;
    node[2]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[2]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[2]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 126_163_127_162
      var       - node[3]
      name      - swish
      operation - swish
      input     - [160, 160, 64, 1]
      output    - [160, 160, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[3], VSI_NN_OP_SWISH, 1, 1, 162);
    node[3]->nn_param.swish.type = VSI_NN_SWISH;
    node[3]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 138_148
      var       - node[4]
      name      - 138
      operation - convolution
      input     - [160, 160, 64, 1]
      filter    - [1, 1, 64, 32]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[4], VSI_NN_OP_CONV2D, 3, 1, 148);
    node[4]->nn_param.conv2d.ksize[0] = 1;
    node[4]->nn_param.conv2d.ksize[1] = 1;
    node[4]->nn_param.conv2d.weights = 32;
    node[4]->nn_param.conv2d.stride[0] = 1;
    node[4]->nn_param.conv2d.stride[1] = 1;
    node[4]->nn_param.conv2d.pad[0] = 0;
    node[4]->nn_param.conv2d.pad[1] = 0;
    node[4]->nn_param.conv2d.pad[2] = 0;
    node[4]->nn_param.conv2d.pad[3] = 0;
    node[4]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[4]->nn_param.conv2d.group = 1;
    node[4]->nn_param.conv2d.dilation[0] = 1;
    node[4]->nn_param.conv2d.dilation[1] = 1;
    node[4]->nn_param.conv2d.multiplier = 0;
    node[4]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[4]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[4]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 128_173
      var       - node[5]
      name      - 128
      operation - convolution
      input     - [160, 160, 64, 1]
      filter    - [1, 1, 64, 32]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[5], VSI_NN_OP_CONV2D, 3, 1, 173);
    node[5]->nn_param.conv2d.ksize[0] = 1;
    node[5]->nn_param.conv2d.ksize[1] = 1;
    node[5]->nn_param.conv2d.weights = 32;
    node[5]->nn_param.conv2d.stride[0] = 1;
    node[5]->nn_param.conv2d.stride[1] = 1;
    node[5]->nn_param.conv2d.pad[0] = 0;
    node[5]->nn_param.conv2d.pad[1] = 0;
    node[5]->nn_param.conv2d.pad[2] = 0;
    node[5]->nn_param.conv2d.pad[3] = 0;
    node[5]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[5]->nn_param.conv2d.group = 1;
    node[5]->nn_param.conv2d.dilation[0] = 1;
    node[5]->nn_param.conv2d.dilation[1] = 1;
    node[5]->nn_param.conv2d.multiplier = 0;
    node[5]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[5]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[5]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 139_149_140_135
      var       - node[6]
      name      - swish
      operation - swish
      input     - [160, 160, 32, 1]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[6], VSI_NN_OP_SWISH, 1, 1, 135);
    node[6]->nn_param.swish.type = VSI_NN_SWISH;
    node[6]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 129_174_130_160
      var       - node[7]
      name      - swish
      operation - swish
      input     - [160, 160, 32, 1]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[7], VSI_NN_OP_SWISH, 1, 1, 160);
    node[7]->nn_param.swish.type = VSI_NN_SWISH;
    node[7]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 131_195
      var       - node[8]
      name      - 131
      operation - convolution
      input     - [160, 160, 32, 1]
      filter    - [1, 1, 32, 32]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[8], VSI_NN_OP_CONV2D, 3, 1, 195);
    node[8]->nn_param.conv2d.ksize[0] = 1;
    node[8]->nn_param.conv2d.ksize[1] = 1;
    node[8]->nn_param.conv2d.weights = 32;
    node[8]->nn_param.conv2d.stride[0] = 1;
    node[8]->nn_param.conv2d.stride[1] = 1;
    node[8]->nn_param.conv2d.pad[0] = 0;
    node[8]->nn_param.conv2d.pad[1] = 0;
    node[8]->nn_param.conv2d.pad[2] = 0;
    node[8]->nn_param.conv2d.pad[3] = 0;
    node[8]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[8]->nn_param.conv2d.group = 1;
    node[8]->nn_param.conv2d.dilation[0] = 1;
    node[8]->nn_param.conv2d.dilation[1] = 1;
    node[8]->nn_param.conv2d.multiplier = 0;
    node[8]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[8]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[8]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 132_192_133_191
      var       - node[9]
      name      - swish
      operation - swish
      input     - [160, 160, 32, 1]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[9], VSI_NN_OP_SWISH, 1, 1, 191);
    node[9]->nn_param.swish.type = VSI_NN_SWISH;
    node[9]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 134_175
      var       - node[10]
      name      - 134
      operation - convolution
      input     - [160, 160, 32, 1]
      filter    - [3, 3, 32, 32]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[10], VSI_NN_OP_CONV2D, 3, 1, 175);
    node[10]->nn_param.conv2d.ksize[0] = 3;
    node[10]->nn_param.conv2d.ksize[1] = 3;
    node[10]->nn_param.conv2d.weights = 32;
    node[10]->nn_param.conv2d.stride[0] = 1;
    node[10]->nn_param.conv2d.stride[1] = 1;
    node[10]->nn_param.conv2d.pad[0] = 1;
    node[10]->nn_param.conv2d.pad[1] = 1;
    node[10]->nn_param.conv2d.pad[2] = 1;
    node[10]->nn_param.conv2d.pad[3] = 1;
    node[10]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[10]->nn_param.conv2d.group = 1;
    node[10]->nn_param.conv2d.dilation[0] = 1;
    node[10]->nn_param.conv2d.dilation[1] = 1;
    node[10]->nn_param.conv2d.multiplier = 0;
    node[10]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[10]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[10]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 135_176_136_161
      var       - node[11]
      name      - swish
      operation - swish
      input     - [160, 160, 32, 1]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[11], VSI_NN_OP_SWISH, 1, 1, 161);
    node[11]->nn_param.swish.type = VSI_NN_SWISH;
    node[11]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 137_147
      var       - node[12]
      name      - 137
      operation - add
      input     - [160, 160, 32, 1]
                  [160, 160, 32, 1]
      output    - [160, 160, 32, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[12], VSI_NN_OP_ADD, 2, 1, 147);

    /*-----------------------------------------
      lid       - 141_134
      var       - node[13]
      name      - 141
      operation - concat
      input     - [160, 160, 32, 1]
                  [160, 160, 32, 1]
      output    - [160, 160, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[13], VSI_NN_OP_CONCAT, 2, 1, 134);
    node[13]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - 142_119
      var       - node[14]
      name      - 142
      operation - convolution
      input     - [160, 160, 64, 1]
      filter    - [1, 1, 64, 64]
      output    - [160, 160, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[14], VSI_NN_OP_CONV2D, 3, 1, 119);
    node[14]->nn_param.conv2d.ksize[0] = 1;
    node[14]->nn_param.conv2d.ksize[1] = 1;
    node[14]->nn_param.conv2d.weights = 64;
    node[14]->nn_param.conv2d.stride[0] = 1;
    node[14]->nn_param.conv2d.stride[1] = 1;
    node[14]->nn_param.conv2d.pad[0] = 0;
    node[14]->nn_param.conv2d.pad[1] = 0;
    node[14]->nn_param.conv2d.pad[2] = 0;
    node[14]->nn_param.conv2d.pad[3] = 0;
    node[14]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[14]->nn_param.conv2d.group = 1;
    node[14]->nn_param.conv2d.dilation[0] = 1;
    node[14]->nn_param.conv2d.dilation[1] = 1;
    node[14]->nn_param.conv2d.multiplier = 0;
    node[14]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[14]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[14]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 143_120_144_109
      var       - node[15]
      name      - swish
      operation - swish
      input     - [160, 160, 64, 1]
      output    - [160, 160, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[15], VSI_NN_OP_SWISH, 1, 1, 109);
    node[15]->nn_param.swish.type = VSI_NN_SWISH;
    node[15]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 145_107
      var       - node[16]
      name      - 145
      operation - convolution
      input     - [160, 160, 64, 1]
      filter    - [3, 3, 64, 128]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[16], VSI_NN_OP_CONV2D, 3, 1, 107);
    node[16]->nn_param.conv2d.ksize[0] = 3;
    node[16]->nn_param.conv2d.ksize[1] = 3;
    node[16]->nn_param.conv2d.weights = 128;
    node[16]->nn_param.conv2d.stride[0] = 2;
    node[16]->nn_param.conv2d.stride[1] = 2;
    node[16]->nn_param.conv2d.pad[0] = 1;
    node[16]->nn_param.conv2d.pad[1] = 1;
    node[16]->nn_param.conv2d.pad[2] = 1;
    node[16]->nn_param.conv2d.pad[3] = 1;
    node[16]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[16]->nn_param.conv2d.group = 1;
    node[16]->nn_param.conv2d.dilation[0] = 1;
    node[16]->nn_param.conv2d.dilation[1] = 1;
    node[16]->nn_param.conv2d.multiplier = 0;
    node[16]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[16]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[16]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 146_108_147_96
      var       - node[17]
      name      - swish
      operation - swish
      input     - [80, 80, 128, 1]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[17], VSI_NN_OP_SWISH, 1, 1, 96);
    node[17]->nn_param.swish.type = VSI_NN_SWISH;
    node[17]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 165_83
      var       - node[18]
      name      - 165
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [1, 1, 128, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[18], VSI_NN_OP_CONV2D, 3, 1, 83);
    node[18]->nn_param.conv2d.ksize[0] = 1;
    node[18]->nn_param.conv2d.ksize[1] = 1;
    node[18]->nn_param.conv2d.weights = 64;
    node[18]->nn_param.conv2d.stride[0] = 1;
    node[18]->nn_param.conv2d.stride[1] = 1;
    node[18]->nn_param.conv2d.pad[0] = 0;
    node[18]->nn_param.conv2d.pad[1] = 0;
    node[18]->nn_param.conv2d.pad[2] = 0;
    node[18]->nn_param.conv2d.pad[3] = 0;
    node[18]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[18]->nn_param.conv2d.group = 1;
    node[18]->nn_param.conv2d.dilation[0] = 1;
    node[18]->nn_param.conv2d.dilation[1] = 1;
    node[18]->nn_param.conv2d.multiplier = 0;
    node[18]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[18]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[18]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 148_128
      var       - node[19]
      name      - 148
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [1, 1, 128, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[19], VSI_NN_OP_CONV2D, 3, 1, 128);
    node[19]->nn_param.conv2d.ksize[0] = 1;
    node[19]->nn_param.conv2d.ksize[1] = 1;
    node[19]->nn_param.conv2d.weights = 64;
    node[19]->nn_param.conv2d.stride[0] = 1;
    node[19]->nn_param.conv2d.stride[1] = 1;
    node[19]->nn_param.conv2d.pad[0] = 0;
    node[19]->nn_param.conv2d.pad[1] = 0;
    node[19]->nn_param.conv2d.pad[2] = 0;
    node[19]->nn_param.conv2d.pad[3] = 0;
    node[19]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[19]->nn_param.conv2d.group = 1;
    node[19]->nn_param.conv2d.dilation[0] = 1;
    node[19]->nn_param.conv2d.dilation[1] = 1;
    node[19]->nn_param.conv2d.multiplier = 0;
    node[19]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[19]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[19]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 166_82_167_79
      var       - node[20]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[20], VSI_NN_OP_SWISH, 1, 1, 79);
    node[20]->nn_param.swish.type = VSI_NN_SWISH;
    node[20]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 149_129_150_115
      var       - node[21]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[21], VSI_NN_OP_SWISH, 1, 1, 115);
    node[21]->nn_param.swish.type = VSI_NN_SWISH;
    node[21]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 151_145
      var       - node[22]
      name      - 151
      operation - convolution
      input     - [80, 80, 64, 1]
      filter    - [1, 1, 64, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[22], VSI_NN_OP_CONV2D, 3, 1, 145);
    node[22]->nn_param.conv2d.ksize[0] = 1;
    node[22]->nn_param.conv2d.ksize[1] = 1;
    node[22]->nn_param.conv2d.weights = 64;
    node[22]->nn_param.conv2d.stride[0] = 1;
    node[22]->nn_param.conv2d.stride[1] = 1;
    node[22]->nn_param.conv2d.pad[0] = 0;
    node[22]->nn_param.conv2d.pad[1] = 0;
    node[22]->nn_param.conv2d.pad[2] = 0;
    node[22]->nn_param.conv2d.pad[3] = 0;
    node[22]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[22]->nn_param.conv2d.group = 1;
    node[22]->nn_param.conv2d.dilation[0] = 1;
    node[22]->nn_param.conv2d.dilation[1] = 1;
    node[22]->nn_param.conv2d.multiplier = 0;
    node[22]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[22]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[22]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 152_146_153_133
      var       - node[23]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[23], VSI_NN_OP_SWISH, 1, 1, 133);
    node[23]->nn_param.swish.type = VSI_NN_SWISH;
    node[23]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 154_130
      var       - node[24]
      name      - 154
      operation - convolution
      input     - [80, 80, 64, 1]
      filter    - [3, 3, 64, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[24], VSI_NN_OP_CONV2D, 3, 1, 130);
    node[24]->nn_param.conv2d.ksize[0] = 3;
    node[24]->nn_param.conv2d.ksize[1] = 3;
    node[24]->nn_param.conv2d.weights = 64;
    node[24]->nn_param.conv2d.stride[0] = 1;
    node[24]->nn_param.conv2d.stride[1] = 1;
    node[24]->nn_param.conv2d.pad[0] = 1;
    node[24]->nn_param.conv2d.pad[1] = 1;
    node[24]->nn_param.conv2d.pad[2] = 1;
    node[24]->nn_param.conv2d.pad[3] = 1;
    node[24]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[24]->nn_param.conv2d.group = 1;
    node[24]->nn_param.conv2d.dilation[0] = 1;
    node[24]->nn_param.conv2d.dilation[1] = 1;
    node[24]->nn_param.conv2d.multiplier = 0;
    node[24]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[24]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[24]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 155_131_156_116
      var       - node[25]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[25], VSI_NN_OP_SWISH, 1, 1, 116);
    node[25]->nn_param.swish.type = VSI_NN_SWISH;
    node[25]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 157_104
      var       - node[26]
      name      - 157
      operation - add
      input     - [80, 80, 64, 1]
                  [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[26], VSI_NN_OP_ADD, 2, 1, 104);

    /*-----------------------------------------
      lid       - 158_132
      var       - node[27]
      name      - 158
      operation - convolution
      input     - [80, 80, 64, 1]
      filter    - [1, 1, 64, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[27], VSI_NN_OP_CONV2D, 3, 1, 132);
    node[27]->nn_param.conv2d.ksize[0] = 1;
    node[27]->nn_param.conv2d.ksize[1] = 1;
    node[27]->nn_param.conv2d.weights = 64;
    node[27]->nn_param.conv2d.stride[0] = 1;
    node[27]->nn_param.conv2d.stride[1] = 1;
    node[27]->nn_param.conv2d.pad[0] = 0;
    node[27]->nn_param.conv2d.pad[1] = 0;
    node[27]->nn_param.conv2d.pad[2] = 0;
    node[27]->nn_param.conv2d.pad[3] = 0;
    node[27]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[27]->nn_param.conv2d.group = 1;
    node[27]->nn_param.conv2d.dilation[0] = 1;
    node[27]->nn_param.conv2d.dilation[1] = 1;
    node[27]->nn_param.conv2d.multiplier = 0;
    node[27]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[27]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[27]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 159_118_160_117
      var       - node[28]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[28], VSI_NN_OP_SWISH, 1, 1, 117);
    node[28]->nn_param.swish.type = VSI_NN_SWISH;
    node[28]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 161_105
      var       - node[29]
      name      - 161
      operation - convolution
      input     - [80, 80, 64, 1]
      filter    - [3, 3, 64, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[29], VSI_NN_OP_CONV2D, 3, 1, 105);
    node[29]->nn_param.conv2d.ksize[0] = 3;
    node[29]->nn_param.conv2d.ksize[1] = 3;
    node[29]->nn_param.conv2d.weights = 64;
    node[29]->nn_param.conv2d.stride[0] = 1;
    node[29]->nn_param.conv2d.stride[1] = 1;
    node[29]->nn_param.conv2d.pad[0] = 1;
    node[29]->nn_param.conv2d.pad[1] = 1;
    node[29]->nn_param.conv2d.pad[2] = 1;
    node[29]->nn_param.conv2d.pad[3] = 1;
    node[29]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[29]->nn_param.conv2d.group = 1;
    node[29]->nn_param.conv2d.dilation[0] = 1;
    node[29]->nn_param.conv2d.dilation[1] = 1;
    node[29]->nn_param.conv2d.multiplier = 0;
    node[29]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[29]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[29]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 162_106_163_95
      var       - node[30]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[30], VSI_NN_OP_SWISH, 1, 1, 95);
    node[30]->nn_param.swish.type = VSI_NN_SWISH;
    node[30]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 164_94
      var       - node[31]
      name      - 164
      operation - add
      input     - [80, 80, 64, 1]
                  [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[31], VSI_NN_OP_ADD, 2, 1, 94);

    /*-----------------------------------------
      lid       - 168_78
      var       - node[32]
      name      - 168
      operation - concat
      input     - [80, 80, 64, 1]
                  [80, 80, 64, 1]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[32], VSI_NN_OP_CONCAT, 2, 1, 78);
    node[32]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - 169_61
      var       - node[33]
      name      - 169
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[33], VSI_NN_OP_CONV2D, 3, 1, 61);
    node[33]->nn_param.conv2d.ksize[0] = 1;
    node[33]->nn_param.conv2d.ksize[1] = 1;
    node[33]->nn_param.conv2d.weights = 128;
    node[33]->nn_param.conv2d.stride[0] = 1;
    node[33]->nn_param.conv2d.stride[1] = 1;
    node[33]->nn_param.conv2d.pad[0] = 0;
    node[33]->nn_param.conv2d.pad[1] = 0;
    node[33]->nn_param.conv2d.pad[2] = 0;
    node[33]->nn_param.conv2d.pad[3] = 0;
    node[33]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[33]->nn_param.conv2d.group = 1;
    node[33]->nn_param.conv2d.dilation[0] = 1;
    node[33]->nn_param.conv2d.dilation[1] = 1;
    node[33]->nn_param.conv2d.multiplier = 0;
    node[33]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[33]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[33]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 170_62_171_47
      var       - node[34]
      name      - swish
      operation - swish
      input     - [80, 80, 128, 1]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[34], VSI_NN_OP_SWISH, 1, 1, 47);
    node[34]->nn_param.swish.type = VSI_NN_SWISH;
    node[34]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 172_159
      var       - node[35]
      name      - 172
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [3, 3, 128, 256]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[35], VSI_NN_OP_CONV2D, 3, 1, 159);
    node[35]->nn_param.conv2d.ksize[0] = 3;
    node[35]->nn_param.conv2d.ksize[1] = 3;
    node[35]->nn_param.conv2d.weights = 256;
    node[35]->nn_param.conv2d.stride[0] = 2;
    node[35]->nn_param.conv2d.stride[1] = 2;
    node[35]->nn_param.conv2d.pad[0] = 1;
    node[35]->nn_param.conv2d.pad[1] = 1;
    node[35]->nn_param.conv2d.pad[2] = 1;
    node[35]->nn_param.conv2d.pad[3] = 1;
    node[35]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[35]->nn_param.conv2d.group = 1;
    node[35]->nn_param.conv2d.dilation[0] = 1;
    node[35]->nn_param.conv2d.dilation[1] = 1;
    node[35]->nn_param.conv2d.multiplier = 0;
    node[35]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[35]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[35]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 173_158_174_157
      var       - node[36]
      name      - swish
      operation - swish
      input     - [40, 40, 256, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[36], VSI_NN_OP_SWISH, 1, 1, 157);
    node[36]->nn_param.swish.type = VSI_NN_SWISH;
    node[36]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 199_144
      var       - node[37]
      name      - 199
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[37], VSI_NN_OP_CONV2D, 3, 1, 144);
    node[37]->nn_param.conv2d.ksize[0] = 1;
    node[37]->nn_param.conv2d.ksize[1] = 1;
    node[37]->nn_param.conv2d.weights = 128;
    node[37]->nn_param.conv2d.stride[0] = 1;
    node[37]->nn_param.conv2d.stride[1] = 1;
    node[37]->nn_param.conv2d.pad[0] = 0;
    node[37]->nn_param.conv2d.pad[1] = 0;
    node[37]->nn_param.conv2d.pad[2] = 0;
    node[37]->nn_param.conv2d.pad[3] = 0;
    node[37]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[37]->nn_param.conv2d.group = 1;
    node[37]->nn_param.conv2d.dilation[0] = 1;
    node[37]->nn_param.conv2d.dilation[1] = 1;
    node[37]->nn_param.conv2d.multiplier = 0;
    node[37]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[37]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[37]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 175_204
      var       - node[38]
      name      - 175
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[38], VSI_NN_OP_CONV2D, 3, 1, 204);
    node[38]->nn_param.conv2d.ksize[0] = 1;
    node[38]->nn_param.conv2d.ksize[1] = 1;
    node[38]->nn_param.conv2d.weights = 128;
    node[38]->nn_param.conv2d.stride[0] = 1;
    node[38]->nn_param.conv2d.stride[1] = 1;
    node[38]->nn_param.conv2d.pad[0] = 0;
    node[38]->nn_param.conv2d.pad[1] = 0;
    node[38]->nn_param.conv2d.pad[2] = 0;
    node[38]->nn_param.conv2d.pad[3] = 0;
    node[38]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[38]->nn_param.conv2d.group = 1;
    node[38]->nn_param.conv2d.dilation[0] = 1;
    node[38]->nn_param.conv2d.dilation[1] = 1;
    node[38]->nn_param.conv2d.multiplier = 0;
    node[38]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[38]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[38]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 200_143_201_142
      var       - node[39]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[39], VSI_NN_OP_SWISH, 1, 1, 142);
    node[39]->nn_param.swish.type = VSI_NN_SWISH;
    node[39]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 176_205_177_199
      var       - node[40]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[40], VSI_NN_OP_SWISH, 1, 1, 199);
    node[40]->nn_param.swish.type = VSI_NN_SWISH;
    node[40]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 178_207
      var       - node[41]
      name      - 178
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[41], VSI_NN_OP_CONV2D, 3, 1, 207);
    node[41]->nn_param.conv2d.ksize[0] = 1;
    node[41]->nn_param.conv2d.ksize[1] = 1;
    node[41]->nn_param.conv2d.weights = 128;
    node[41]->nn_param.conv2d.stride[0] = 1;
    node[41]->nn_param.conv2d.stride[1] = 1;
    node[41]->nn_param.conv2d.pad[0] = 0;
    node[41]->nn_param.conv2d.pad[1] = 0;
    node[41]->nn_param.conv2d.pad[2] = 0;
    node[41]->nn_param.conv2d.pad[3] = 0;
    node[41]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[41]->nn_param.conv2d.group = 1;
    node[41]->nn_param.conv2d.dilation[0] = 1;
    node[41]->nn_param.conv2d.dilation[1] = 1;
    node[41]->nn_param.conv2d.multiplier = 0;
    node[41]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[41]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[41]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 179_206_180_203
      var       - node[42]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[42], VSI_NN_OP_SWISH, 1, 1, 203);
    node[42]->nn_param.swish.type = VSI_NN_SWISH;
    node[42]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 181_202
      var       - node[43]
      name      - 181
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [3, 3, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[43], VSI_NN_OP_CONV2D, 3, 1, 202);
    node[43]->nn_param.conv2d.ksize[0] = 3;
    node[43]->nn_param.conv2d.ksize[1] = 3;
    node[43]->nn_param.conv2d.weights = 128;
    node[43]->nn_param.conv2d.stride[0] = 1;
    node[43]->nn_param.conv2d.stride[1] = 1;
    node[43]->nn_param.conv2d.pad[0] = 1;
    node[43]->nn_param.conv2d.pad[1] = 1;
    node[43]->nn_param.conv2d.pad[2] = 1;
    node[43]->nn_param.conv2d.pad[3] = 1;
    node[43]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[43]->nn_param.conv2d.group = 1;
    node[43]->nn_param.conv2d.dilation[0] = 1;
    node[43]->nn_param.conv2d.dilation[1] = 1;
    node[43]->nn_param.conv2d.multiplier = 0;
    node[43]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[43]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[43]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 182_201_183_200
      var       - node[44]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[44], VSI_NN_OP_SWISH, 1, 1, 200);
    node[44]->nn_param.swish.type = VSI_NN_SWISH;
    node[44]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 184_185
      var       - node[45]
      name      - 184
      operation - add
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[45], VSI_NN_OP_ADD, 2, 1, 185);

    /*-----------------------------------------
      lid       - 185_198
      var       - node[46]
      name      - 185
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[46], VSI_NN_OP_CONV2D, 3, 1, 198);
    node[46]->nn_param.conv2d.ksize[0] = 1;
    node[46]->nn_param.conv2d.ksize[1] = 1;
    node[46]->nn_param.conv2d.weights = 128;
    node[46]->nn_param.conv2d.stride[0] = 1;
    node[46]->nn_param.conv2d.stride[1] = 1;
    node[46]->nn_param.conv2d.pad[0] = 0;
    node[46]->nn_param.conv2d.pad[1] = 0;
    node[46]->nn_param.conv2d.pad[2] = 0;
    node[46]->nn_param.conv2d.pad[3] = 0;
    node[46]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[46]->nn_param.conv2d.group = 1;
    node[46]->nn_param.conv2d.dilation[0] = 1;
    node[46]->nn_param.conv2d.dilation[1] = 1;
    node[46]->nn_param.conv2d.multiplier = 0;
    node[46]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[46]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[46]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 186_196_187_190
      var       - node[47]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[47], VSI_NN_OP_SWISH, 1, 1, 190);
    node[47]->nn_param.swish.type = VSI_NN_SWISH;
    node[47]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 188_189
      var       - node[48]
      name      - 188
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [3, 3, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[48], VSI_NN_OP_CONV2D, 3, 1, 189);
    node[48]->nn_param.conv2d.ksize[0] = 3;
    node[48]->nn_param.conv2d.ksize[1] = 3;
    node[48]->nn_param.conv2d.weights = 128;
    node[48]->nn_param.conv2d.stride[0] = 1;
    node[48]->nn_param.conv2d.stride[1] = 1;
    node[48]->nn_param.conv2d.pad[0] = 1;
    node[48]->nn_param.conv2d.pad[1] = 1;
    node[48]->nn_param.conv2d.pad[2] = 1;
    node[48]->nn_param.conv2d.pad[3] = 1;
    node[48]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[48]->nn_param.conv2d.group = 1;
    node[48]->nn_param.conv2d.dilation[0] = 1;
    node[48]->nn_param.conv2d.dilation[1] = 1;
    node[48]->nn_param.conv2d.multiplier = 0;
    node[48]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[48]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[48]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 189_188_190_186
      var       - node[49]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[49], VSI_NN_OP_SWISH, 1, 1, 186);
    node[49]->nn_param.swish.type = VSI_NN_SWISH;
    node[49]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 191_168
      var       - node[50]
      name      - 191
      operation - add
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[50], VSI_NN_OP_ADD, 2, 1, 168);

    /*-----------------------------------------
      lid       - 192_187
      var       - node[51]
      name      - 192
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[51], VSI_NN_OP_CONV2D, 3, 1, 187);
    node[51]->nn_param.conv2d.ksize[0] = 1;
    node[51]->nn_param.conv2d.ksize[1] = 1;
    node[51]->nn_param.conv2d.weights = 128;
    node[51]->nn_param.conv2d.stride[0] = 1;
    node[51]->nn_param.conv2d.stride[1] = 1;
    node[51]->nn_param.conv2d.pad[0] = 0;
    node[51]->nn_param.conv2d.pad[1] = 0;
    node[51]->nn_param.conv2d.pad[2] = 0;
    node[51]->nn_param.conv2d.pad[3] = 0;
    node[51]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[51]->nn_param.conv2d.group = 1;
    node[51]->nn_param.conv2d.dilation[0] = 1;
    node[51]->nn_param.conv2d.dilation[1] = 1;
    node[51]->nn_param.conv2d.multiplier = 0;
    node[51]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[51]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[51]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 193_172_194_171
      var       - node[52]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[52], VSI_NN_OP_SWISH, 1, 1, 171);
    node[52]->nn_param.swish.type = VSI_NN_SWISH;
    node[52]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 195_169
      var       - node[53]
      name      - 195
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [3, 3, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[53], VSI_NN_OP_CONV2D, 3, 1, 169);
    node[53]->nn_param.conv2d.ksize[0] = 3;
    node[53]->nn_param.conv2d.ksize[1] = 3;
    node[53]->nn_param.conv2d.weights = 128;
    node[53]->nn_param.conv2d.stride[0] = 1;
    node[53]->nn_param.conv2d.stride[1] = 1;
    node[53]->nn_param.conv2d.pad[0] = 1;
    node[53]->nn_param.conv2d.pad[1] = 1;
    node[53]->nn_param.conv2d.pad[2] = 1;
    node[53]->nn_param.conv2d.pad[3] = 1;
    node[53]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[53]->nn_param.conv2d.group = 1;
    node[53]->nn_param.conv2d.dilation[0] = 1;
    node[53]->nn_param.conv2d.dilation[1] = 1;
    node[53]->nn_param.conv2d.multiplier = 0;
    node[53]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[53]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[53]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 196_170_197_156
      var       - node[54]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[54], VSI_NN_OP_SWISH, 1, 1, 156);
    node[54]->nn_param.swish.type = VSI_NN_SWISH;
    node[54]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 198_155
      var       - node[55]
      name      - 198
      operation - add
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[55], VSI_NN_OP_ADD, 2, 1, 155);

    /*-----------------------------------------
      lid       - 202_141
      var       - node[56]
      name      - 202
      operation - concat
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[56], VSI_NN_OP_CONCAT, 2, 1, 141);
    node[56]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - 203_126
      var       - node[57]
      name      - 203
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 256]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[57], VSI_NN_OP_CONV2D, 3, 1, 126);
    node[57]->nn_param.conv2d.ksize[0] = 1;
    node[57]->nn_param.conv2d.ksize[1] = 1;
    node[57]->nn_param.conv2d.weights = 256;
    node[57]->nn_param.conv2d.stride[0] = 1;
    node[57]->nn_param.conv2d.stride[1] = 1;
    node[57]->nn_param.conv2d.pad[0] = 0;
    node[57]->nn_param.conv2d.pad[1] = 0;
    node[57]->nn_param.conv2d.pad[2] = 0;
    node[57]->nn_param.conv2d.pad[3] = 0;
    node[57]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[57]->nn_param.conv2d.group = 1;
    node[57]->nn_param.conv2d.dilation[0] = 1;
    node[57]->nn_param.conv2d.dilation[1] = 1;
    node[57]->nn_param.conv2d.multiplier = 0;
    node[57]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[57]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[57]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 204_127_205_114
      var       - node[58]
      name      - swish
      operation - swish
      input     - [40, 40, 256, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[58], VSI_NN_OP_SWISH, 1, 1, 114);
    node[58]->nn_param.swish.type = VSI_NN_SWISH;
    node[58]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 206_166
      var       - node[59]
      name      - 206
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [3, 3, 256, 512]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[59], VSI_NN_OP_CONV2D, 3, 1, 166);
    node[59]->nn_param.conv2d.ksize[0] = 3;
    node[59]->nn_param.conv2d.ksize[1] = 3;
    node[59]->nn_param.conv2d.weights = 512;
    node[59]->nn_param.conv2d.stride[0] = 2;
    node[59]->nn_param.conv2d.stride[1] = 2;
    node[59]->nn_param.conv2d.pad[0] = 1;
    node[59]->nn_param.conv2d.pad[1] = 1;
    node[59]->nn_param.conv2d.pad[2] = 1;
    node[59]->nn_param.conv2d.pad[3] = 1;
    node[59]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[59]->nn_param.conv2d.group = 1;
    node[59]->nn_param.conv2d.dilation[0] = 1;
    node[59]->nn_param.conv2d.dilation[1] = 1;
    node[59]->nn_param.conv2d.multiplier = 0;
    node[59]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[59]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[59]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 207_167_208_154
      var       - node[60]
      name      - swish
      operation - swish
      input     - [20, 20, 512, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[60], VSI_NN_OP_SWISH, 1, 1, 154);
    node[60]->nn_param.swish.type = VSI_NN_SWISH;
    node[60]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 219_151
      var       - node[61]
      name      - 219
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[61], VSI_NN_OP_CONV2D, 3, 1, 151);
    node[61]->nn_param.conv2d.ksize[0] = 1;
    node[61]->nn_param.conv2d.ksize[1] = 1;
    node[61]->nn_param.conv2d.weights = 256;
    node[61]->nn_param.conv2d.stride[0] = 1;
    node[61]->nn_param.conv2d.stride[1] = 1;
    node[61]->nn_param.conv2d.pad[0] = 0;
    node[61]->nn_param.conv2d.pad[1] = 0;
    node[61]->nn_param.conv2d.pad[2] = 0;
    node[61]->nn_param.conv2d.pad[3] = 0;
    node[61]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[61]->nn_param.conv2d.group = 1;
    node[61]->nn_param.conv2d.dilation[0] = 1;
    node[61]->nn_param.conv2d.dilation[1] = 1;
    node[61]->nn_param.conv2d.multiplier = 0;
    node[61]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[61]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[61]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 209_179
      var       - node[62]
      name      - 209
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[62], VSI_NN_OP_CONV2D, 3, 1, 179);
    node[62]->nn_param.conv2d.ksize[0] = 1;
    node[62]->nn_param.conv2d.ksize[1] = 1;
    node[62]->nn_param.conv2d.weights = 256;
    node[62]->nn_param.conv2d.stride[0] = 1;
    node[62]->nn_param.conv2d.stride[1] = 1;
    node[62]->nn_param.conv2d.pad[0] = 0;
    node[62]->nn_param.conv2d.pad[1] = 0;
    node[62]->nn_param.conv2d.pad[2] = 0;
    node[62]->nn_param.conv2d.pad[3] = 0;
    node[62]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[62]->nn_param.conv2d.group = 1;
    node[62]->nn_param.conv2d.dilation[0] = 1;
    node[62]->nn_param.conv2d.dilation[1] = 1;
    node[62]->nn_param.conv2d.multiplier = 0;
    node[62]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[62]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[62]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 220_152_221_137
      var       - node[63]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[63], VSI_NN_OP_SWISH, 1, 1, 137);
    node[63]->nn_param.swish.type = VSI_NN_SWISH;
    node[63]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 210_180_211_164
      var       - node[64]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[64], VSI_NN_OP_SWISH, 1, 1, 164);
    node[64]->nn_param.swish.type = VSI_NN_SWISH;
    node[64]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 212_197
      var       - node[65]
      name      - 212
      operation - convolution
      input     - [20, 20, 256, 1]
      filter    - [1, 1, 256, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[65], VSI_NN_OP_CONV2D, 3, 1, 197);
    node[65]->nn_param.conv2d.ksize[0] = 1;
    node[65]->nn_param.conv2d.ksize[1] = 1;
    node[65]->nn_param.conv2d.weights = 256;
    node[65]->nn_param.conv2d.stride[0] = 1;
    node[65]->nn_param.conv2d.stride[1] = 1;
    node[65]->nn_param.conv2d.pad[0] = 0;
    node[65]->nn_param.conv2d.pad[1] = 0;
    node[65]->nn_param.conv2d.pad[2] = 0;
    node[65]->nn_param.conv2d.pad[3] = 0;
    node[65]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[65]->nn_param.conv2d.group = 1;
    node[65]->nn_param.conv2d.dilation[0] = 1;
    node[65]->nn_param.conv2d.dilation[1] = 1;
    node[65]->nn_param.conv2d.multiplier = 0;
    node[65]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[65]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[65]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 213_184_214_183
      var       - node[66]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[66], VSI_NN_OP_SWISH, 1, 1, 183);
    node[66]->nn_param.swish.type = VSI_NN_SWISH;
    node[66]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 215_181
      var       - node[67]
      name      - 215
      operation - convolution
      input     - [20, 20, 256, 1]
      filter    - [3, 3, 256, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[67], VSI_NN_OP_CONV2D, 3, 1, 181);
    node[67]->nn_param.conv2d.ksize[0] = 3;
    node[67]->nn_param.conv2d.ksize[1] = 3;
    node[67]->nn_param.conv2d.weights = 256;
    node[67]->nn_param.conv2d.stride[0] = 1;
    node[67]->nn_param.conv2d.stride[1] = 1;
    node[67]->nn_param.conv2d.pad[0] = 1;
    node[67]->nn_param.conv2d.pad[1] = 1;
    node[67]->nn_param.conv2d.pad[2] = 1;
    node[67]->nn_param.conv2d.pad[3] = 1;
    node[67]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[67]->nn_param.conv2d.group = 1;
    node[67]->nn_param.conv2d.dilation[0] = 1;
    node[67]->nn_param.conv2d.dilation[1] = 1;
    node[67]->nn_param.conv2d.multiplier = 0;
    node[67]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[67]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[67]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 216_182_217_165
      var       - node[68]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[68], VSI_NN_OP_SWISH, 1, 1, 165);
    node[68]->nn_param.swish.type = VSI_NN_SWISH;
    node[68]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 218_150
      var       - node[69]
      name      - 218
      operation - add
      input     - [20, 20, 256, 1]
                  [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[69], VSI_NN_OP_ADD, 2, 1, 150);

    /*-----------------------------------------
      lid       - 222_136
      var       - node[70]
      name      - 222
      operation - concat
      input     - [20, 20, 256, 1]
                  [20, 20, 256, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[70], VSI_NN_OP_CONCAT, 2, 1, 136);
    node[70]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - 223_121
      var       - node[71]
      name      - 223
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 512]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[71], VSI_NN_OP_CONV2D, 3, 1, 121);
    node[71]->nn_param.conv2d.ksize[0] = 1;
    node[71]->nn_param.conv2d.ksize[1] = 1;
    node[71]->nn_param.conv2d.weights = 512;
    node[71]->nn_param.conv2d.stride[0] = 1;
    node[71]->nn_param.conv2d.stride[1] = 1;
    node[71]->nn_param.conv2d.pad[0] = 0;
    node[71]->nn_param.conv2d.pad[1] = 0;
    node[71]->nn_param.conv2d.pad[2] = 0;
    node[71]->nn_param.conv2d.pad[3] = 0;
    node[71]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[71]->nn_param.conv2d.group = 1;
    node[71]->nn_param.conv2d.dilation[0] = 1;
    node[71]->nn_param.conv2d.dilation[1] = 1;
    node[71]->nn_param.conv2d.multiplier = 0;
    node[71]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[71]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[71]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 224_122_225_110
      var       - node[72]
      name      - swish
      operation - swish
      input     - [20, 20, 512, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[72], VSI_NN_OP_SWISH, 1, 1, 110);
    node[72]->nn_param.swish.type = VSI_NN_SWISH;
    node[72]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 226_100
      var       - node[73]
      name      - 226
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[73], VSI_NN_OP_CONV2D, 3, 1, 100);
    node[73]->nn_param.conv2d.ksize[0] = 1;
    node[73]->nn_param.conv2d.ksize[1] = 1;
    node[73]->nn_param.conv2d.weights = 256;
    node[73]->nn_param.conv2d.stride[0] = 1;
    node[73]->nn_param.conv2d.stride[1] = 1;
    node[73]->nn_param.conv2d.pad[0] = 0;
    node[73]->nn_param.conv2d.pad[1] = 0;
    node[73]->nn_param.conv2d.pad[2] = 0;
    node[73]->nn_param.conv2d.pad[3] = 0;
    node[73]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[73]->nn_param.conv2d.group = 1;
    node[73]->nn_param.conv2d.dilation[0] = 1;
    node[73]->nn_param.conv2d.dilation[1] = 1;
    node[73]->nn_param.conv2d.multiplier = 0;
    node[73]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[73]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[73]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 227_99_228_97
      var       - node[74]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[74], VSI_NN_OP_SWISH, 1, 1, 97);
    node[74]->nn_param.swish.type = VSI_NN_SWISH;
    node[74]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 229_98
      var       - node[75]
      name      - 229
      operation - pooling
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[75], VSI_NN_OP_POOL, 1, 1, 98);
    node[75]->nn_param.pool.ksize[0] = 5;
    node[75]->nn_param.pool.ksize[1] = 5;
    node[75]->nn_param.pool.stride[0] = 1;
    node[75]->nn_param.pool.stride[1] = 1;
    node[75]->nn_param.pool.pad[0] = 2;
    node[75]->nn_param.pool.pad[1] = 2;
    node[75]->nn_param.pool.pad[2] = 2;
    node[75]->nn_param.pool.pad[3] = 2;
    node[75]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[75]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[75]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 230_89
      var       - node[76]
      name      - 230
      operation - pooling
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[76], VSI_NN_OP_POOL, 1, 1, 89);
    node[76]->nn_param.pool.ksize[0] = 5;
    node[76]->nn_param.pool.ksize[1] = 5;
    node[76]->nn_param.pool.stride[0] = 1;
    node[76]->nn_param.pool.stride[1] = 1;
    node[76]->nn_param.pool.pad[0] = 2;
    node[76]->nn_param.pool.pad[1] = 2;
    node[76]->nn_param.pool.pad[2] = 2;
    node[76]->nn_param.pool.pad[3] = 2;
    node[76]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[76]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[76]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 231_88
      var       - node[77]
      name      - 231
      operation - pooling
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[77], VSI_NN_OP_POOL, 1, 1, 88);
    node[77]->nn_param.pool.ksize[0] = 5;
    node[77]->nn_param.pool.ksize[1] = 5;
    node[77]->nn_param.pool.stride[0] = 1;
    node[77]->nn_param.pool.stride[1] = 1;
    node[77]->nn_param.pool.pad[0] = 2;
    node[77]->nn_param.pool.pad[1] = 2;
    node[77]->nn_param.pool.pad[2] = 2;
    node[77]->nn_param.pool.pad[3] = 2;
    node[77]->nn_param.pool.type = VX_CONVOLUTIONAL_NETWORK_POOLING_MAX;
    node[77]->nn_param.pool.round_type = VSI_NN_ROUND_FLOOR;
    node[77]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 232_85
      var       - node[78]
      name      - 232
      operation - concat
      input     - [20, 20, 256, 1]
                  [20, 20, 256, 1]
                  [20, 20, 256, 1]
                  [20, 20, 256, 1]
      output    - [20, 20, 1024, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[78], VSI_NN_OP_CONCAT, 4, 1, 85);
    node[78]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - 233_84
      var       - node[79]
      name      - 233
      operation - convolution
      input     - [20, 20, 1024, 1]
      filter    - [1, 1, 1024, 512]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[79], VSI_NN_OP_CONV2D, 3, 1, 84);
    node[79]->nn_param.conv2d.ksize[0] = 1;
    node[79]->nn_param.conv2d.ksize[1] = 1;
    node[79]->nn_param.conv2d.weights = 512;
    node[79]->nn_param.conv2d.stride[0] = 1;
    node[79]->nn_param.conv2d.stride[1] = 1;
    node[79]->nn_param.conv2d.pad[0] = 0;
    node[79]->nn_param.conv2d.pad[1] = 0;
    node[79]->nn_param.conv2d.pad[2] = 0;
    node[79]->nn_param.conv2d.pad[3] = 0;
    node[79]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[79]->nn_param.conv2d.group = 1;
    node[79]->nn_param.conv2d.dilation[0] = 1;
    node[79]->nn_param.conv2d.dilation[1] = 1;
    node[79]->nn_param.conv2d.multiplier = 0;
    node[79]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[79]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[79]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 234_68_235_67
      var       - node[80]
      name      - swish
      operation - swish
      input     - [20, 20, 512, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[80], VSI_NN_OP_SWISH, 1, 1, 67);
    node[80]->nn_param.swish.type = VSI_NN_SWISH;
    node[80]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 236_51
      var       - node[81]
      name      - 236
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[81], VSI_NN_OP_CONV2D, 3, 1, 51);
    node[81]->nn_param.conv2d.ksize[0] = 1;
    node[81]->nn_param.conv2d.ksize[1] = 1;
    node[81]->nn_param.conv2d.weights = 256;
    node[81]->nn_param.conv2d.stride[0] = 1;
    node[81]->nn_param.conv2d.stride[1] = 1;
    node[81]->nn_param.conv2d.pad[0] = 0;
    node[81]->nn_param.conv2d.pad[1] = 0;
    node[81]->nn_param.conv2d.pad[2] = 0;
    node[81]->nn_param.conv2d.pad[3] = 0;
    node[81]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[81]->nn_param.conv2d.group = 1;
    node[81]->nn_param.conv2d.dilation[0] = 1;
    node[81]->nn_param.conv2d.dilation[1] = 1;
    node[81]->nn_param.conv2d.multiplier = 0;
    node[81]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[81]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[81]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 237_52_238_39
      var       - node[82]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[82], VSI_NN_OP_SWISH, 1, 1, 39);
    node[82]->nn_param.swish.type = VSI_NN_SWISH;
    node[82]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 243_125
      var       - node[83]
      name      - 243
      operation - image_resize
      input     - [20, 20, 256, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[83], VSI_NN_OP_RESIZE, 1, 1, 125);
    node[83]->nn_param.resize.type = VSI_NN_INTERPOLATION_NEAREST_NEIGHBOR;
    node[83]->nn_param.resize.factor = 0.0;
    node[83]->nn_param.resize.align_corners = FALSE;
    node[83]->nn_param.resize.half_pixel_centers = FALSE;
    node[83]->nn_param.resize.size[0] = 40;
    node[83]->nn_param.resize.size[1] = 40;

    /*-----------------------------------------
      lid       - 244_113
      var       - node[84]
      name      - 244
      operation - concat
      input     - [40, 40, 256, 1]
                  [40, 40, 256, 1]
      output    - [40, 40, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[84], VSI_NN_OP_CONCAT, 2, 1, 113);
    node[84]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - 254_102
      var       - node[85]
      name      - 254
      operation - convolution
      input     - [40, 40, 512, 1]
      filter    - [1, 1, 512, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[85], VSI_NN_OP_CONV2D, 3, 1, 102);
    node[85]->nn_param.conv2d.ksize[0] = 1;
    node[85]->nn_param.conv2d.ksize[1] = 1;
    node[85]->nn_param.conv2d.weights = 128;
    node[85]->nn_param.conv2d.stride[0] = 1;
    node[85]->nn_param.conv2d.stride[1] = 1;
    node[85]->nn_param.conv2d.pad[0] = 0;
    node[85]->nn_param.conv2d.pad[1] = 0;
    node[85]->nn_param.conv2d.pad[2] = 0;
    node[85]->nn_param.conv2d.pad[3] = 0;
    node[85]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[85]->nn_param.conv2d.group = 1;
    node[85]->nn_param.conv2d.dilation[0] = 1;
    node[85]->nn_param.conv2d.dilation[1] = 1;
    node[85]->nn_param.conv2d.multiplier = 0;
    node[85]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[85]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[85]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 245_153
      var       - node[86]
      name      - 245
      operation - convolution
      input     - [40, 40, 512, 1]
      filter    - [1, 1, 512, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[86], VSI_NN_OP_CONV2D, 3, 1, 153);
    node[86]->nn_param.conv2d.ksize[0] = 1;
    node[86]->nn_param.conv2d.ksize[1] = 1;
    node[86]->nn_param.conv2d.weights = 128;
    node[86]->nn_param.conv2d.stride[0] = 1;
    node[86]->nn_param.conv2d.stride[1] = 1;
    node[86]->nn_param.conv2d.pad[0] = 0;
    node[86]->nn_param.conv2d.pad[1] = 0;
    node[86]->nn_param.conv2d.pad[2] = 0;
    node[86]->nn_param.conv2d.pad[3] = 0;
    node[86]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[86]->nn_param.conv2d.group = 1;
    node[86]->nn_param.conv2d.dilation[0] = 1;
    node[86]->nn_param.conv2d.dilation[1] = 1;
    node[86]->nn_param.conv2d.multiplier = 0;
    node[86]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[86]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[86]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 255_103_256_93
      var       - node[87]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[87], VSI_NN_OP_SWISH, 1, 1, 93);
    node[87]->nn_param.swish.type = VSI_NN_SWISH;
    node[87]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 246_140_247_139
      var       - node[88]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[88], VSI_NN_OP_SWISH, 1, 1, 139);
    node[88]->nn_param.swish.type = VSI_NN_SWISH;
    node[88]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 248_138
      var       - node[89]
      name      - 248
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[89], VSI_NN_OP_CONV2D, 3, 1, 138);
    node[89]->nn_param.conv2d.ksize[0] = 1;
    node[89]->nn_param.conv2d.ksize[1] = 1;
    node[89]->nn_param.conv2d.weights = 128;
    node[89]->nn_param.conv2d.stride[0] = 1;
    node[89]->nn_param.conv2d.stride[1] = 1;
    node[89]->nn_param.conv2d.pad[0] = 0;
    node[89]->nn_param.conv2d.pad[1] = 0;
    node[89]->nn_param.conv2d.pad[2] = 0;
    node[89]->nn_param.conv2d.pad[3] = 0;
    node[89]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[89]->nn_param.conv2d.group = 1;
    node[89]->nn_param.conv2d.dilation[0] = 1;
    node[89]->nn_param.conv2d.dilation[1] = 1;
    node[89]->nn_param.conv2d.multiplier = 0;
    node[89]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[89]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[89]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 249_124_250_123
      var       - node[90]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[90], VSI_NN_OP_SWISH, 1, 1, 123);
    node[90]->nn_param.swish.type = VSI_NN_SWISH;
    node[90]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 251_111
      var       - node[91]
      name      - 251
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [3, 3, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[91], VSI_NN_OP_CONV2D, 3, 1, 111);
    node[91]->nn_param.conv2d.ksize[0] = 3;
    node[91]->nn_param.conv2d.ksize[1] = 3;
    node[91]->nn_param.conv2d.weights = 128;
    node[91]->nn_param.conv2d.stride[0] = 1;
    node[91]->nn_param.conv2d.stride[1] = 1;
    node[91]->nn_param.conv2d.pad[0] = 1;
    node[91]->nn_param.conv2d.pad[1] = 1;
    node[91]->nn_param.conv2d.pad[2] = 1;
    node[91]->nn_param.conv2d.pad[3] = 1;
    node[91]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[91]->nn_param.conv2d.group = 1;
    node[91]->nn_param.conv2d.dilation[0] = 1;
    node[91]->nn_param.conv2d.dilation[1] = 1;
    node[91]->nn_param.conv2d.multiplier = 0;
    node[91]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[91]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[91]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 252_112_253_101
      var       - node[92]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[92], VSI_NN_OP_SWISH, 1, 1, 101);
    node[92]->nn_param.swish.type = VSI_NN_SWISH;
    node[92]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 257_91
      var       - node[93]
      name      - 257
      operation - concat
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[93], VSI_NN_OP_CONCAT, 2, 1, 91);
    node[93]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - 258_90
      var       - node[94]
      name      - 258
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 256]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[94], VSI_NN_OP_CONV2D, 3, 1, 90);
    node[94]->nn_param.conv2d.ksize[0] = 1;
    node[94]->nn_param.conv2d.ksize[1] = 1;
    node[94]->nn_param.conv2d.weights = 256;
    node[94]->nn_param.conv2d.stride[0] = 1;
    node[94]->nn_param.conv2d.stride[1] = 1;
    node[94]->nn_param.conv2d.pad[0] = 0;
    node[94]->nn_param.conv2d.pad[1] = 0;
    node[94]->nn_param.conv2d.pad[2] = 0;
    node[94]->nn_param.conv2d.pad[3] = 0;
    node[94]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[94]->nn_param.conv2d.group = 1;
    node[94]->nn_param.conv2d.dilation[0] = 1;
    node[94]->nn_param.conv2d.dilation[1] = 1;
    node[94]->nn_param.conv2d.multiplier = 0;
    node[94]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[94]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[94]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 259_74_260_73
      var       - node[95]
      name      - swish
      operation - swish
      input     - [40, 40, 256, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[95], VSI_NN_OP_SWISH, 1, 1, 73);
    node[95]->nn_param.swish.type = VSI_NN_SWISH;
    node[95]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 261_56
      var       - node[96]
      name      - 261
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[96], VSI_NN_OP_CONV2D, 3, 1, 56);
    node[96]->nn_param.conv2d.ksize[0] = 1;
    node[96]->nn_param.conv2d.ksize[1] = 1;
    node[96]->nn_param.conv2d.weights = 128;
    node[96]->nn_param.conv2d.stride[0] = 1;
    node[96]->nn_param.conv2d.stride[1] = 1;
    node[96]->nn_param.conv2d.pad[0] = 0;
    node[96]->nn_param.conv2d.pad[1] = 0;
    node[96]->nn_param.conv2d.pad[2] = 0;
    node[96]->nn_param.conv2d.pad[3] = 0;
    node[96]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[96]->nn_param.conv2d.group = 1;
    node[96]->nn_param.conv2d.dilation[0] = 1;
    node[96]->nn_param.conv2d.dilation[1] = 1;
    node[96]->nn_param.conv2d.multiplier = 0;
    node[96]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[96]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[96]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 262_57_263_43
      var       - node[97]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[97], VSI_NN_OP_SWISH, 1, 1, 43);
    node[97]->nn_param.swish.type = VSI_NN_SWISH;
    node[97]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 268_60
      var       - node[98]
      name      - 268
      operation - image_resize
      input     - [40, 40, 128, 1]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[98], VSI_NN_OP_RESIZE, 1, 1, 60);
    node[98]->nn_param.resize.type = VSI_NN_INTERPOLATION_NEAREST_NEIGHBOR;
    node[98]->nn_param.resize.factor = 0.0;
    node[98]->nn_param.resize.align_corners = FALSE;
    node[98]->nn_param.resize.half_pixel_centers = FALSE;
    node[98]->nn_param.resize.size[0] = 80;
    node[98]->nn_param.resize.size[1] = 80;

    /*-----------------------------------------
      lid       - 269_46
      var       - node[99]
      name      - 269
      operation - concat
      input     - [80, 80, 128, 1]
                  [80, 80, 128, 1]
      output    - [80, 80, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[99], VSI_NN_OP_CONCAT, 2, 1, 46);
    node[99]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - 279_34
      var       - node[100]
      name      - 279
      operation - convolution
      input     - [80, 80, 256, 1]
      filter    - [1, 1, 256, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[100], VSI_NN_OP_CONV2D, 3, 1, 34);
    node[100]->nn_param.conv2d.ksize[0] = 1;
    node[100]->nn_param.conv2d.ksize[1] = 1;
    node[100]->nn_param.conv2d.weights = 64;
    node[100]->nn_param.conv2d.stride[0] = 1;
    node[100]->nn_param.conv2d.stride[1] = 1;
    node[100]->nn_param.conv2d.pad[0] = 0;
    node[100]->nn_param.conv2d.pad[1] = 0;
    node[100]->nn_param.conv2d.pad[2] = 0;
    node[100]->nn_param.conv2d.pad[3] = 0;
    node[100]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[100]->nn_param.conv2d.group = 1;
    node[100]->nn_param.conv2d.dilation[0] = 1;
    node[100]->nn_param.conv2d.dilation[1] = 1;
    node[100]->nn_param.conv2d.multiplier = 0;
    node[100]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[100]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[100]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 270_92
      var       - node[101]
      name      - 270
      operation - convolution
      input     - [80, 80, 256, 1]
      filter    - [1, 1, 256, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[101], VSI_NN_OP_CONV2D, 3, 1, 92);
    node[101]->nn_param.conv2d.ksize[0] = 1;
    node[101]->nn_param.conv2d.ksize[1] = 1;
    node[101]->nn_param.conv2d.weights = 64;
    node[101]->nn_param.conv2d.stride[0] = 1;
    node[101]->nn_param.conv2d.stride[1] = 1;
    node[101]->nn_param.conv2d.pad[0] = 0;
    node[101]->nn_param.conv2d.pad[1] = 0;
    node[101]->nn_param.conv2d.pad[2] = 0;
    node[101]->nn_param.conv2d.pad[3] = 0;
    node[101]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[101]->nn_param.conv2d.group = 1;
    node[101]->nn_param.conv2d.dilation[0] = 1;
    node[101]->nn_param.conv2d.dilation[1] = 1;
    node[101]->nn_param.conv2d.multiplier = 0;
    node[101]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[101]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[101]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 280_35_281_26
      var       - node[102]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[102], VSI_NN_OP_SWISH, 1, 1, 26);
    node[102]->nn_param.swish.type = VSI_NN_SWISH;
    node[102]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 271_77_272_76
      var       - node[103]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[103], VSI_NN_OP_SWISH, 1, 1, 76);
    node[103]->nn_param.swish.type = VSI_NN_SWISH;
    node[103]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 273_75
      var       - node[104]
      name      - 273
      operation - convolution
      input     - [80, 80, 64, 1]
      filter    - [1, 1, 64, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[104], VSI_NN_OP_CONV2D, 3, 1, 75);
    node[104]->nn_param.conv2d.ksize[0] = 1;
    node[104]->nn_param.conv2d.ksize[1] = 1;
    node[104]->nn_param.conv2d.weights = 64;
    node[104]->nn_param.conv2d.stride[0] = 1;
    node[104]->nn_param.conv2d.stride[1] = 1;
    node[104]->nn_param.conv2d.pad[0] = 0;
    node[104]->nn_param.conv2d.pad[1] = 0;
    node[104]->nn_param.conv2d.pad[2] = 0;
    node[104]->nn_param.conv2d.pad[3] = 0;
    node[104]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[104]->nn_param.conv2d.group = 1;
    node[104]->nn_param.conv2d.dilation[0] = 1;
    node[104]->nn_param.conv2d.dilation[1] = 1;
    node[104]->nn_param.conv2d.multiplier = 0;
    node[104]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[104]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[104]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 274_59_275_58
      var       - node[105]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[105], VSI_NN_OP_SWISH, 1, 1, 58);
    node[105]->nn_param.swish.type = VSI_NN_SWISH;
    node[105]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 276_44
      var       - node[106]
      name      - 276
      operation - convolution
      input     - [80, 80, 64, 1]
      filter    - [3, 3, 64, 64]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[106], VSI_NN_OP_CONV2D, 3, 1, 44);
    node[106]->nn_param.conv2d.ksize[0] = 3;
    node[106]->nn_param.conv2d.ksize[1] = 3;
    node[106]->nn_param.conv2d.weights = 64;
    node[106]->nn_param.conv2d.stride[0] = 1;
    node[106]->nn_param.conv2d.stride[1] = 1;
    node[106]->nn_param.conv2d.pad[0] = 1;
    node[106]->nn_param.conv2d.pad[1] = 1;
    node[106]->nn_param.conv2d.pad[2] = 1;
    node[106]->nn_param.conv2d.pad[3] = 1;
    node[106]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[106]->nn_param.conv2d.group = 1;
    node[106]->nn_param.conv2d.dilation[0] = 1;
    node[106]->nn_param.conv2d.dilation[1] = 1;
    node[106]->nn_param.conv2d.multiplier = 0;
    node[106]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[106]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[106]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 277_45_278_33
      var       - node[107]
      name      - swish
      operation - swish
      input     - [80, 80, 64, 1]
      output    - [80, 80, 64, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[107], VSI_NN_OP_SWISH, 1, 1, 33);
    node[107]->nn_param.swish.type = VSI_NN_SWISH;
    node[107]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 282_25
      var       - node[108]
      name      - 282
      operation - concat
      input     - [80, 80, 64, 1]
                  [80, 80, 64, 1]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[108], VSI_NN_OP_CONCAT, 2, 1, 25);
    node[108]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - 283_19
      var       - node[109]
      name      - 283
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[109], VSI_NN_OP_CONV2D, 3, 1, 19);
    node[109]->nn_param.conv2d.ksize[0] = 1;
    node[109]->nn_param.conv2d.ksize[1] = 1;
    node[109]->nn_param.conv2d.weights = 128;
    node[109]->nn_param.conv2d.stride[0] = 1;
    node[109]->nn_param.conv2d.stride[1] = 1;
    node[109]->nn_param.conv2d.pad[0] = 0;
    node[109]->nn_param.conv2d.pad[1] = 0;
    node[109]->nn_param.conv2d.pad[2] = 0;
    node[109]->nn_param.conv2d.pad[3] = 0;
    node[109]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[109]->nn_param.conv2d.group = 1;
    node[109]->nn_param.conv2d.dilation[0] = 1;
    node[109]->nn_param.conv2d.dilation[1] = 1;
    node[109]->nn_param.conv2d.multiplier = 0;
    node[109]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[109]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[109]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 284_20_285_14
      var       - node[110]
      name      - swish
      operation - swish
      input     - [80, 80, 128, 1]
      output    - [80, 80, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[110], VSI_NN_OP_SWISH, 1, 1, 14);
    node[110]->nn_param.swish.type = VSI_NN_SWISH;
    node[110]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 326_11
      var       - node[111]
      name      - 326
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [1, 1, 128, 255]
      output    - [80, 80, 255, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[111], VSI_NN_OP_CONV2D, 3, 1, 11);
    node[111]->nn_param.conv2d.ksize[0] = 1;
    node[111]->nn_param.conv2d.ksize[1] = 1;
    node[111]->nn_param.conv2d.weights = 255;
    node[111]->nn_param.conv2d.stride[0] = 1;
    node[111]->nn_param.conv2d.stride[1] = 1;
    node[111]->nn_param.conv2d.pad[0] = 0;
    node[111]->nn_param.conv2d.pad[1] = 0;
    node[111]->nn_param.conv2d.pad[2] = 0;
    node[111]->nn_param.conv2d.pad[3] = 0;
    node[111]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[111]->nn_param.conv2d.group = 1;
    node[111]->nn_param.conv2d.dilation[0] = 1;
    node[111]->nn_param.conv2d.dilation[1] = 1;
    node[111]->nn_param.conv2d.multiplier = 0;
    node[111]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[111]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[111]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 286_71
      var       - node[112]
      name      - 286
      operation - convolution
      input     - [80, 80, 128, 1]
      filter    - [3, 3, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[112], VSI_NN_OP_CONV2D, 3, 1, 71);
    node[112]->nn_param.conv2d.ksize[0] = 3;
    node[112]->nn_param.conv2d.ksize[1] = 3;
    node[112]->nn_param.conv2d.weights = 128;
    node[112]->nn_param.conv2d.stride[0] = 2;
    node[112]->nn_param.conv2d.stride[1] = 2;
    node[112]->nn_param.conv2d.pad[0] = 1;
    node[112]->nn_param.conv2d.pad[1] = 1;
    node[112]->nn_param.conv2d.pad[2] = 1;
    node[112]->nn_param.conv2d.pad[3] = 1;
    node[112]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[112]->nn_param.conv2d.group = 1;
    node[112]->nn_param.conv2d.dilation[0] = 1;
    node[112]->nn_param.conv2d.dilation[1] = 1;
    node[112]->nn_param.conv2d.multiplier = 0;
    node[112]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[112]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[112]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 349_8
      var       - node[113]
      name      - 349
      operation - reshape
      input     - [80, 80, 255, 1]
      output    - [80, 80, 85, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[113], VSI_NN_OP_RESHAPE2, 1, 1, 8);
    node[113]->nn_param.reshape2.size = shape_1;
    node[113]->nn_param.reshape2.dim_num = 5;

    /*-----------------------------------------
      lid       - 287_72_288_55
      var       - node[114]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[114], VSI_NN_OP_SWISH, 1, 1, 55);
    node[114]->nn_param.swish.type = VSI_NN_SWISH;
    node[114]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 350_5
      var       - node[115]
      name      - 350
      operation - permute
      input     - [80, 80, 85, 3, 1]
      output    - [85, 80, 80, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[115], VSI_NN_OP_PERMUTE, 1, 1, 5);
    node[115]->nn_param.permute.perm = perm_1;
    node[115]->nn_param.permute.dim_num = 5;

    /*-----------------------------------------
      lid       - 289_42
      var       - node[116]
      name      - 289
      operation - concat
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[116], VSI_NN_OP_CONCAT, 2, 1, 42);
    node[116]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - 299_31
      var       - node[117]
      name      - 299
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[117], VSI_NN_OP_CONV2D, 3, 1, 31);
    node[117]->nn_param.conv2d.ksize[0] = 1;
    node[117]->nn_param.conv2d.ksize[1] = 1;
    node[117]->nn_param.conv2d.weights = 128;
    node[117]->nn_param.conv2d.stride[0] = 1;
    node[117]->nn_param.conv2d.stride[1] = 1;
    node[117]->nn_param.conv2d.pad[0] = 0;
    node[117]->nn_param.conv2d.pad[1] = 0;
    node[117]->nn_param.conv2d.pad[2] = 0;
    node[117]->nn_param.conv2d.pad[3] = 0;
    node[117]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[117]->nn_param.conv2d.group = 1;
    node[117]->nn_param.conv2d.dilation[0] = 1;
    node[117]->nn_param.conv2d.dilation[1] = 1;
    node[117]->nn_param.conv2d.multiplier = 0;
    node[117]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[117]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[117]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 290_86
      var       - node[118]
      name      - 290
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[118], VSI_NN_OP_CONV2D, 3, 1, 86);
    node[118]->nn_param.conv2d.ksize[0] = 1;
    node[118]->nn_param.conv2d.ksize[1] = 1;
    node[118]->nn_param.conv2d.weights = 128;
    node[118]->nn_param.conv2d.stride[0] = 1;
    node[118]->nn_param.conv2d.stride[1] = 1;
    node[118]->nn_param.conv2d.pad[0] = 0;
    node[118]->nn_param.conv2d.pad[1] = 0;
    node[118]->nn_param.conv2d.pad[2] = 0;
    node[118]->nn_param.conv2d.pad[3] = 0;
    node[118]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[118]->nn_param.conv2d.group = 1;
    node[118]->nn_param.conv2d.dilation[0] = 1;
    node[118]->nn_param.conv2d.dilation[1] = 1;
    node[118]->nn_param.conv2d.multiplier = 0;
    node[118]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[118]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[118]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 300_32_301_24
      var       - node[119]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[119], VSI_NN_OP_SWISH, 1, 1, 24);
    node[119]->nn_param.swish.type = VSI_NN_SWISH;
    node[119]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 291_87_292_70
      var       - node[120]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[120], VSI_NN_OP_SWISH, 1, 1, 70);
    node[120]->nn_param.swish.type = VSI_NN_SWISH;
    node[120]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 293_69
      var       - node[121]
      name      - 293
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [1, 1, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[121], VSI_NN_OP_CONV2D, 3, 1, 69);
    node[121]->nn_param.conv2d.ksize[0] = 1;
    node[121]->nn_param.conv2d.ksize[1] = 1;
    node[121]->nn_param.conv2d.weights = 128;
    node[121]->nn_param.conv2d.stride[0] = 1;
    node[121]->nn_param.conv2d.stride[1] = 1;
    node[121]->nn_param.conv2d.pad[0] = 0;
    node[121]->nn_param.conv2d.pad[1] = 0;
    node[121]->nn_param.conv2d.pad[2] = 0;
    node[121]->nn_param.conv2d.pad[3] = 0;
    node[121]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[121]->nn_param.conv2d.group = 1;
    node[121]->nn_param.conv2d.dilation[0] = 1;
    node[121]->nn_param.conv2d.dilation[1] = 1;
    node[121]->nn_param.conv2d.multiplier = 0;
    node[121]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[121]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[121]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 294_54_295_53
      var       - node[122]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[122], VSI_NN_OP_SWISH, 1, 1, 53);
    node[122]->nn_param.swish.type = VSI_NN_SWISH;
    node[122]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 296_40
      var       - node[123]
      name      - 296
      operation - convolution
      input     - [40, 40, 128, 1]
      filter    - [3, 3, 128, 128]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[123], VSI_NN_OP_CONV2D, 3, 1, 40);
    node[123]->nn_param.conv2d.ksize[0] = 3;
    node[123]->nn_param.conv2d.ksize[1] = 3;
    node[123]->nn_param.conv2d.weights = 128;
    node[123]->nn_param.conv2d.stride[0] = 1;
    node[123]->nn_param.conv2d.stride[1] = 1;
    node[123]->nn_param.conv2d.pad[0] = 1;
    node[123]->nn_param.conv2d.pad[1] = 1;
    node[123]->nn_param.conv2d.pad[2] = 1;
    node[123]->nn_param.conv2d.pad[3] = 1;
    node[123]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[123]->nn_param.conv2d.group = 1;
    node[123]->nn_param.conv2d.dilation[0] = 1;
    node[123]->nn_param.conv2d.dilation[1] = 1;
    node[123]->nn_param.conv2d.multiplier = 0;
    node[123]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[123]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[123]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 297_41_298_30
      var       - node[124]
      name      - swish
      operation - swish
      input     - [40, 40, 128, 1]
      output    - [40, 40, 128, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[124], VSI_NN_OP_SWISH, 1, 1, 30);
    node[124]->nn_param.swish.type = VSI_NN_SWISH;
    node[124]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 302_23
      var       - node[125]
      name      - 302
      operation - concat
      input     - [40, 40, 128, 1]
                  [40, 40, 128, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[125], VSI_NN_OP_CONCAT, 2, 1, 23);
    node[125]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - 303_17
      var       - node[126]
      name      - 303
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 256]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[126], VSI_NN_OP_CONV2D, 3, 1, 17);
    node[126]->nn_param.conv2d.ksize[0] = 1;
    node[126]->nn_param.conv2d.ksize[1] = 1;
    node[126]->nn_param.conv2d.weights = 256;
    node[126]->nn_param.conv2d.stride[0] = 1;
    node[126]->nn_param.conv2d.stride[1] = 1;
    node[126]->nn_param.conv2d.pad[0] = 0;
    node[126]->nn_param.conv2d.pad[1] = 0;
    node[126]->nn_param.conv2d.pad[2] = 0;
    node[126]->nn_param.conv2d.pad[3] = 0;
    node[126]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[126]->nn_param.conv2d.group = 1;
    node[126]->nn_param.conv2d.dilation[0] = 1;
    node[126]->nn_param.conv2d.dilation[1] = 1;
    node[126]->nn_param.conv2d.multiplier = 0;
    node[126]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[126]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[126]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 304_18_305_13
      var       - node[127]
      name      - swish
      operation - swish
      input     - [40, 40, 256, 1]
      output    - [40, 40, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[127], VSI_NN_OP_SWISH, 1, 1, 13);
    node[127]->nn_param.swish.type = VSI_NN_SWISH;
    node[127]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 474_10
      var       - node[128]
      name      - 474
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [1, 1, 256, 255]
      output    - [40, 40, 255, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[128], VSI_NN_OP_CONV2D, 3, 1, 10);
    node[128]->nn_param.conv2d.ksize[0] = 1;
    node[128]->nn_param.conv2d.ksize[1] = 1;
    node[128]->nn_param.conv2d.weights = 255;
    node[128]->nn_param.conv2d.stride[0] = 1;
    node[128]->nn_param.conv2d.stride[1] = 1;
    node[128]->nn_param.conv2d.pad[0] = 0;
    node[128]->nn_param.conv2d.pad[1] = 0;
    node[128]->nn_param.conv2d.pad[2] = 0;
    node[128]->nn_param.conv2d.pad[3] = 0;
    node[128]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[128]->nn_param.conv2d.group = 1;
    node[128]->nn_param.conv2d.dilation[0] = 1;
    node[128]->nn_param.conv2d.dilation[1] = 1;
    node[128]->nn_param.conv2d.multiplier = 0;
    node[128]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[128]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[128]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 306_65
      var       - node[129]
      name      - 306
      operation - convolution
      input     - [40, 40, 256, 1]
      filter    - [3, 3, 256, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[129], VSI_NN_OP_CONV2D, 3, 1, 65);
    node[129]->nn_param.conv2d.ksize[0] = 3;
    node[129]->nn_param.conv2d.ksize[1] = 3;
    node[129]->nn_param.conv2d.weights = 256;
    node[129]->nn_param.conv2d.stride[0] = 2;
    node[129]->nn_param.conv2d.stride[1] = 2;
    node[129]->nn_param.conv2d.pad[0] = 1;
    node[129]->nn_param.conv2d.pad[1] = 1;
    node[129]->nn_param.conv2d.pad[2] = 1;
    node[129]->nn_param.conv2d.pad[3] = 1;
    node[129]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[129]->nn_param.conv2d.group = 1;
    node[129]->nn_param.conv2d.dilation[0] = 1;
    node[129]->nn_param.conv2d.dilation[1] = 1;
    node[129]->nn_param.conv2d.multiplier = 0;
    node[129]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[129]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[129]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 497_7
      var       - node[130]
      name      - 497
      operation - reshape
      input     - [40, 40, 255, 1]
      output    - [40, 40, 85, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[130], VSI_NN_OP_RESHAPE2, 1, 1, 7);
    node[130]->nn_param.reshape2.size = shape_2;
    node[130]->nn_param.reshape2.dim_num = 5;

    /*-----------------------------------------
      lid       - 307_66_308_50
      var       - node[131]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[131], VSI_NN_OP_SWISH, 1, 1, 50);
    node[131]->nn_param.swish.type = VSI_NN_SWISH;
    node[131]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 498_4
      var       - node[132]
      name      - 498
      operation - permute
      input     - [40, 40, 85, 3, 1]
      output    - [85, 40, 40, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[132], VSI_NN_OP_PERMUTE, 1, 1, 4);
    node[132]->nn_param.permute.perm = perm_2;
    node[132]->nn_param.permute.dim_num = 5;

    /*-----------------------------------------
      lid       - 309_38
      var       - node[133]
      name      - 309
      operation - concat
      input     - [20, 20, 256, 1]
                  [20, 20, 256, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[133], VSI_NN_OP_CONCAT, 2, 1, 38);
    node[133]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - 319_28
      var       - node[134]
      name      - 319
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[134], VSI_NN_OP_CONV2D, 3, 1, 28);
    node[134]->nn_param.conv2d.ksize[0] = 1;
    node[134]->nn_param.conv2d.ksize[1] = 1;
    node[134]->nn_param.conv2d.weights = 256;
    node[134]->nn_param.conv2d.stride[0] = 1;
    node[134]->nn_param.conv2d.stride[1] = 1;
    node[134]->nn_param.conv2d.pad[0] = 0;
    node[134]->nn_param.conv2d.pad[1] = 0;
    node[134]->nn_param.conv2d.pad[2] = 0;
    node[134]->nn_param.conv2d.pad[3] = 0;
    node[134]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[134]->nn_param.conv2d.group = 1;
    node[134]->nn_param.conv2d.dilation[0] = 1;
    node[134]->nn_param.conv2d.dilation[1] = 1;
    node[134]->nn_param.conv2d.multiplier = 0;
    node[134]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[134]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[134]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 310_80
      var       - node[135]
      name      - 310
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[135], VSI_NN_OP_CONV2D, 3, 1, 80);
    node[135]->nn_param.conv2d.ksize[0] = 1;
    node[135]->nn_param.conv2d.ksize[1] = 1;
    node[135]->nn_param.conv2d.weights = 256;
    node[135]->nn_param.conv2d.stride[0] = 1;
    node[135]->nn_param.conv2d.stride[1] = 1;
    node[135]->nn_param.conv2d.pad[0] = 0;
    node[135]->nn_param.conv2d.pad[1] = 0;
    node[135]->nn_param.conv2d.pad[2] = 0;
    node[135]->nn_param.conv2d.pad[3] = 0;
    node[135]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[135]->nn_param.conv2d.group = 1;
    node[135]->nn_param.conv2d.dilation[0] = 1;
    node[135]->nn_param.conv2d.dilation[1] = 1;
    node[135]->nn_param.conv2d.multiplier = 0;
    node[135]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[135]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[135]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 320_29_321_22
      var       - node[136]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[136], VSI_NN_OP_SWISH, 1, 1, 22);
    node[136]->nn_param.swish.type = VSI_NN_SWISH;
    node[136]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 311_81_312_64
      var       - node[137]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[137], VSI_NN_OP_SWISH, 1, 1, 64);
    node[137]->nn_param.swish.type = VSI_NN_SWISH;
    node[137]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 313_63
      var       - node[138]
      name      - 313
      operation - convolution
      input     - [20, 20, 256, 1]
      filter    - [1, 1, 256, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[138], VSI_NN_OP_CONV2D, 3, 1, 63);
    node[138]->nn_param.conv2d.ksize[0] = 1;
    node[138]->nn_param.conv2d.ksize[1] = 1;
    node[138]->nn_param.conv2d.weights = 256;
    node[138]->nn_param.conv2d.stride[0] = 1;
    node[138]->nn_param.conv2d.stride[1] = 1;
    node[138]->nn_param.conv2d.pad[0] = 0;
    node[138]->nn_param.conv2d.pad[1] = 0;
    node[138]->nn_param.conv2d.pad[2] = 0;
    node[138]->nn_param.conv2d.pad[3] = 0;
    node[138]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[138]->nn_param.conv2d.group = 1;
    node[138]->nn_param.conv2d.dilation[0] = 1;
    node[138]->nn_param.conv2d.dilation[1] = 1;
    node[138]->nn_param.conv2d.multiplier = 0;
    node[138]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[138]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[138]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 314_49_315_48
      var       - node[139]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[139], VSI_NN_OP_SWISH, 1, 1, 48);
    node[139]->nn_param.swish.type = VSI_NN_SWISH;
    node[139]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 316_36
      var       - node[140]
      name      - 316
      operation - convolution
      input     - [20, 20, 256, 1]
      filter    - [3, 3, 256, 256]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[140], VSI_NN_OP_CONV2D, 3, 1, 36);
    node[140]->nn_param.conv2d.ksize[0] = 3;
    node[140]->nn_param.conv2d.ksize[1] = 3;
    node[140]->nn_param.conv2d.weights = 256;
    node[140]->nn_param.conv2d.stride[0] = 1;
    node[140]->nn_param.conv2d.stride[1] = 1;
    node[140]->nn_param.conv2d.pad[0] = 1;
    node[140]->nn_param.conv2d.pad[1] = 1;
    node[140]->nn_param.conv2d.pad[2] = 1;
    node[140]->nn_param.conv2d.pad[3] = 1;
    node[140]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[140]->nn_param.conv2d.group = 1;
    node[140]->nn_param.conv2d.dilation[0] = 1;
    node[140]->nn_param.conv2d.dilation[1] = 1;
    node[140]->nn_param.conv2d.multiplier = 0;
    node[140]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[140]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[140]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 317_37_318_27
      var       - node[141]
      name      - swish
      operation - swish
      input     - [20, 20, 256, 1]
      output    - [20, 20, 256, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[141], VSI_NN_OP_SWISH, 1, 1, 27);
    node[141]->nn_param.swish.type = VSI_NN_SWISH;
    node[141]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 322_21
      var       - node[142]
      name      - 322
      operation - concat
      input     - [20, 20, 256, 1]
                  [20, 20, 256, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[142], VSI_NN_OP_CONCAT, 2, 1, 21);
    node[142]->nn_param.concat.axis = 2;

    /*-----------------------------------------
      lid       - 323_15
      var       - node[143]
      name      - 323
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 512]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[143], VSI_NN_OP_CONV2D, 3, 1, 15);
    node[143]->nn_param.conv2d.ksize[0] = 1;
    node[143]->nn_param.conv2d.ksize[1] = 1;
    node[143]->nn_param.conv2d.weights = 512;
    node[143]->nn_param.conv2d.stride[0] = 1;
    node[143]->nn_param.conv2d.stride[1] = 1;
    node[143]->nn_param.conv2d.pad[0] = 0;
    node[143]->nn_param.conv2d.pad[1] = 0;
    node[143]->nn_param.conv2d.pad[2] = 0;
    node[143]->nn_param.conv2d.pad[3] = 0;
    node[143]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[143]->nn_param.conv2d.group = 1;
    node[143]->nn_param.conv2d.dilation[0] = 1;
    node[143]->nn_param.conv2d.dilation[1] = 1;
    node[143]->nn_param.conv2d.multiplier = 0;
    node[143]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[143]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[143]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 324_16_325_12
      var       - node[144]
      name      - swish
      operation - swish
      input     - [20, 20, 512, 1]
      output    - [20, 20, 512, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[144], VSI_NN_OP_SWISH, 1, 1, 12);
    node[144]->nn_param.swish.type = VSI_NN_SWISH;
    node[144]->nn_param.swish.beta = 1.0;

    /*-----------------------------------------
      lid       - 622_9
      var       - node[145]
      name      - 622
      operation - convolution
      input     - [20, 20, 512, 1]
      filter    - [1, 1, 512, 255]
      output    - [20, 20, 255, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[145], VSI_NN_OP_CONV2D, 3, 1, 9);
    node[145]->nn_param.conv2d.ksize[0] = 1;
    node[145]->nn_param.conv2d.ksize[1] = 1;
    node[145]->nn_param.conv2d.weights = 255;
    node[145]->nn_param.conv2d.stride[0] = 1;
    node[145]->nn_param.conv2d.stride[1] = 1;
    node[145]->nn_param.conv2d.pad[0] = 0;
    node[145]->nn_param.conv2d.pad[1] = 0;
    node[145]->nn_param.conv2d.pad[2] = 0;
    node[145]->nn_param.conv2d.pad[3] = 0;
    node[145]->nn_param.conv2d.pad_mode = VSI_NN_PAD_MODE_CONSTANT;
    node[145]->nn_param.conv2d.group = 1;
    node[145]->nn_param.conv2d.dilation[0] = 1;
    node[145]->nn_param.conv2d.dilation[1] = 1;
    node[145]->nn_param.conv2d.multiplier = 0;
    node[145]->vx_param.overflow_policy = VX_CONVERT_POLICY_SATURATE;
    node[145]->vx_param.rounding_policy = VX_ROUND_POLICY_TO_NEAREST_EVEN;
    node[145]->vx_param.down_scale_size_rounding = VX_CONVOLUTIONAL_NETWORK_DS_SIZE_ROUNDING_FLOOR;

    /*-----------------------------------------
      lid       - 645_6
      var       - node[146]
      name      - 645
      operation - reshape
      input     - [20, 20, 255, 1]
      output    - [20, 20, 85, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[146], VSI_NN_OP_RESHAPE2, 1, 1, 6);
    node[146]->nn_param.reshape2.size = shape_3;
    node[146]->nn_param.reshape2.dim_num = 5;

    /*-----------------------------------------
      lid       - 646_3
      var       - node[147]
      name      - 646
      operation - permute
      input     - [20, 20, 85, 3, 1]
      output    - [85, 20, 20, 3, 1]
    -----------------------------------------*/
    NEW_VXNODE(node[147], VSI_NN_OP_PERMUTE, 1, 1, 3);
    node[147]->nn_param.permute.perm = perm_3;
    node[147]->nn_param.permute.dim_num = 5;

    }
    else
    {
    NEW_VXNODE(node[0], VSI_NN_OP_NBG, 1, 3, 0);
    node[0]->nn_param.nbg.type = VSI_NN_NBG_FILE;
    node[0]->nn_param.nbg.url = data_file_name;

    }

/*-----------------------------------------
  Tensor initialize
 -----------------------------------------*/
    attr.dtype.fmt = VSI_NN_DIM_FMT_NCHW;
    /* @attach_350/out0_0:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 85;
    attr.size[1] = 80;
    attr.size[2] = 80;
    attr.size[3] = 3;
    attr.size[4] = 1;
    attr.dim_num = 5;
    attr.dtype.scale = 0.08591902256011963;
    attr.dtype.zero_point = 211;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[0], attr, VSI_NN_TYPE_UINT8);

    /* @attach_498/out0_1:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 85;
    attr.size[1] = 40;
    attr.size[2] = 40;
    attr.size[3] = 3;
    attr.size[4] = 1;
    attr.dim_num = 5;
    attr.dtype.scale = 0.07161629945039749;
    attr.dtype.zero_point = 204;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[1], attr, VSI_NN_TYPE_UINT8);

    /* @attach_646/out0_2:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 85;
    attr.size[1] = 20;
    attr.size[2] = 20;
    attr.size[3] = 3;
    attr.size[4] = 1;
    attr.dim_num = 5;
    attr.dtype.scale = 0.07200625538825989;
    attr.dtype.zero_point = 196;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[2], attr, VSI_NN_TYPE_UINT8);

    /* @images_208:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 640;
    attr.size[1] = 640;
    attr.size[2] = 3;
    attr.size[3] = 1;
    attr.dim_num = 4;
    attr.dtype.scale = 0.003921569790691137;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_NORM_TENSOR(norm_tensor[3], attr, VSI_NN_TYPE_UINT8);



    if( !inference_with_nbg )
    {
    /* @122_193:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 6;
    attr.size[1] = 6;
    attr.size[2] = 3;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.2132832407951355;
    attr.dtype.zero_point = 121;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[0], attr, VSI_NN_TYPE_UINT8, 128, 3456);

    /* @122_193:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0008364050881937146;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[1], attr, VSI_NN_TYPE_INT32, 0, 128);

    /* @125_177:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00812322087585926;
    attr.dtype.zero_point = 131;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[2], attr, VSI_NN_TYPE_UINT8, 3840, 18432);

    /* @125_177:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.001312685664743185;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[3], attr, VSI_NN_TYPE_INT32, 3584, 256);

    /* @138_148:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007109948433935642;
    attr.dtype.zero_point = 157;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[4], attr, VSI_NN_TYPE_UINT8, 35072, 2048);

    /* @138_148:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.001637898851186037;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[5], attr, VSI_NN_TYPE_INT32, 34944, 128);

    /* @128_173:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.005300343502312899;
    attr.dtype.zero_point = 191;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[6], attr, VSI_NN_TYPE_UINT8, 22400, 2048);

    /* @128_173:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0012210252461954951;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[7], attr, VSI_NN_TYPE_INT32, 22272, 128);

    /* @131_195:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 32;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.057911574840545654;
    attr.dtype.zero_point = 112;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[8], attr, VSI_NN_TYPE_UINT8, 24576, 1024);

    /* @131_195:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0009597493917681277;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[9], attr, VSI_NN_TYPE_INT32, 24448, 128);

    /* @134_175:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 32;
    attr.size[3] = 32;
    attr.dim_num = 4;
    attr.dtype.scale = 0.006764058489352465;
    attr.dtype.zero_point = 113;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[10], attr, VSI_NN_TYPE_UINT8, 25728, 9216);

    /* @134_175:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 32;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00037801117287017405;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[11], attr, VSI_NN_TYPE_INT32, 25600, 128);

    /* @142_119:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.006935855373740196;
    attr.dtype.zero_point = 151;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[12], attr, VSI_NN_TYPE_UINT8, 37376, 4096);

    /* @142_119:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0005776546895503998;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[13], attr, VSI_NN_TYPE_INT32, 37120, 256);

    /* @145_107:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0021823032293468714;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[14], attr, VSI_NN_TYPE_UINT8, 41984, 73728);

    /* @145_107:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00010846508666872978;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[15], attr, VSI_NN_TYPE_INT32, 41472, 512);

    /* @165_83:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.012595177628099918;
    attr.dtype.zero_point = 156;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[16], attr, VSI_NN_TYPE_UINT8, 207360, 8192);

    /* @165_83:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002829277655109763;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[17], attr, VSI_NN_TYPE_INT32, 207104, 256);

    /* @148_128:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0036936281248927116;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[18], attr, VSI_NN_TYPE_UINT8, 115968, 8192);

    /* @148_128:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 8.297064050566405e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[19], attr, VSI_NN_TYPE_INT32, 115712, 256);

    /* @151_145:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.022251758724451065;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[20], attr, VSI_NN_TYPE_UINT8, 124416, 4096);

    /* @151_145:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.000186585690244101;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[21], attr, VSI_NN_TYPE_INT32, 124160, 256);

    /* @154_130:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0033081118017435074;
    attr.dtype.zero_point = 157;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[22], attr, VSI_NN_TYPE_UINT8, 128768, 36864);

    /* @154_130:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 7.942136289784685e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[23], attr, VSI_NN_TYPE_INT32, 128512, 256);

    /* @158_132:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.016224373131990433;
    attr.dtype.zero_point = 95;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[24], attr, VSI_NN_TYPE_UINT8, 165888, 4096);

    /* @158_132:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002146248589269817;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[25], attr, VSI_NN_TYPE_INT32, 165632, 256);

    /* @161_105:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007488714065402746;
    attr.dtype.zero_point = 138;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[26], attr, VSI_NN_TYPE_UINT8, 170240, 36864);

    /* @161_105:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00016568377031944692;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[27], attr, VSI_NN_TYPE_INT32, 169984, 256);

    /* @169_61:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.006058035884052515;
    attr.dtype.zero_point = 124;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[28], attr, VSI_NN_TYPE_UINT8, 216064, 16384);

    /* @169_61:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00017854322504717857;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[29], attr, VSI_NN_TYPE_INT32, 215552, 512);

    /* @172_159:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.005526114255189896;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[30], attr, VSI_NN_TYPE_UINT8, 233472, 294912);

    /* @172_159:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00011246116628171876;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[31], attr, VSI_NN_TYPE_INT32, 232448, 1024);

    /* @199_144:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.009754646569490433;
    attr.dtype.zero_point = 146;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[32], attr, VSI_NN_TYPE_UINT8, 1056768, 32768);

    /* @199_144:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00019850931130349636;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[33], attr, VSI_NN_TYPE_INT32, 1056256, 512);

    /* @175_204:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007966560311615467;
    attr.dtype.zero_point = 184;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[34], attr, VSI_NN_TYPE_UINT8, 528896, 32768);

    /* @175_204:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001621213450562209;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[35], attr, VSI_NN_TYPE_INT32, 528384, 512);

    /* @178_207:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.021737486124038696;
    attr.dtype.zero_point = 131;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[36], attr, VSI_NN_TYPE_UINT8, 562176, 16384);

    /* @178_207:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00017586899048183113;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[37], attr, VSI_NN_TYPE_INT32, 561664, 512);

    /* @181_202:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.003179156919941306;
    attr.dtype.zero_point = 157;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[38], attr, VSI_NN_TYPE_UINT8, 579072, 147456);

    /* @181_202:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 7.574301707791165e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[39], attr, VSI_NN_TYPE_INT32, 578560, 512);

    /* @185_198:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.016731588169932365;
    attr.dtype.zero_point = 118;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[40], attr, VSI_NN_TYPE_UINT8, 727040, 16384);

    /* @185_198:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00022287596948444843;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[41], attr, VSI_NN_TYPE_INT32, 726528, 512);

    /* @188_189:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.004429674241691828;
    attr.dtype.zero_point = 148;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[42], attr, VSI_NN_TYPE_UINT8, 743936, 147456);

    /* @188_189:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00010350747470511124;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[43], attr, VSI_NN_TYPE_INT32, 743424, 512);

    /* @192_187:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0084226094186306;
    attr.dtype.zero_point = 129;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[44], attr, VSI_NN_TYPE_UINT8, 891904, 16384);

    /* @192_187:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00020578462863340974;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[45], attr, VSI_NN_TYPE_INT32, 891392, 512);

    /* @195_169:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007165605202317238;
    attr.dtype.zero_point = 117;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[46], attr, VSI_NN_TYPE_UINT8, 908800, 147456);

    /* @195_169:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00016271449567284435;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[47], attr, VSI_NN_TYPE_INT32, 908288, 512);

    /* @203_126:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.003918573725968599;
    attr.dtype.zero_point = 109;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[48], attr, VSI_NN_TYPE_UINT8, 1090560, 65536);

    /* @203_126:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001553761394461617;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[49], attr, VSI_NN_TYPE_INT32, 1089536, 1024);

    /* @206_166:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 256;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0035942504182457924;
    attr.dtype.zero_point = 109;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[50], attr, VSI_NN_TYPE_UINT8, 1158144, 1179648);

    /* @206_166:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 8.205093763535842e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[51], attr, VSI_NN_TYPE_INT32, 1156096, 2048);

    /* @219_151:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00909903459250927;
    attr.dtype.zero_point = 119;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[52], attr, VSI_NN_TYPE_UINT8, 3128320, 131072);

    /* @219_151:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00021942924649920315;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[53], attr, VSI_NN_TYPE_INT32, 3127296, 1024);

    /* @209_179:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00430411659181118;
    attr.dtype.zero_point = 145;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[54], attr, VSI_NN_TYPE_UINT8, 2338816, 131072);

    /* @209_179:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001037966285366565;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[55], attr, VSI_NN_TYPE_INT32, 2337792, 1024);

    /* @212_197:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0191442109644413;
    attr.dtype.zero_point = 130;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[56], attr, VSI_NN_TYPE_UINT8, 2470912, 65536);

    /* @212_197:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0004369619127828628;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[57], attr, VSI_NN_TYPE_INT32, 2469888, 1024);

    /* @215_181:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0036736060865223408;
    attr.dtype.zero_point = 147;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[58], attr, VSI_NN_TYPE_UINT8, 2537472, 589824);

    /* @215_181:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001390485413139686;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[59], attr, VSI_NN_TYPE_INT32, 2536448, 1024);

    /* @223_121:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.005403044633567333;
    attr.dtype.zero_point = 107;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[60], attr, VSI_NN_TYPE_UINT8, 3261440, 262144);

    /* @223_121:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00019223999697715044;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[61], attr, VSI_NN_TYPE_INT32, 3259392, 2048);

    /* @226_100:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.004150948021560907;
    attr.dtype.zero_point = 159;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[62], attr, VSI_NN_TYPE_UINT8, 3524608, 131072);

    /* @226_100:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 8.748436812311411e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[63], attr, VSI_NN_TYPE_INT32, 3523584, 1024);

    /* @233_84:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 1024;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00451302994042635;
    attr.dtype.zero_point = 124;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[64], attr, VSI_NN_TYPE_UINT8, 3657728, 524288);

    /* @233_84:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00010289785859640688;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[65], attr, VSI_NN_TYPE_INT32, 3655680, 2048);

    /* @236_51:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.010493258945643902;
    attr.dtype.zero_point = 165;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[66], attr, VSI_NN_TYPE_UINT8, 4183040, 131072);

    /* @236_51:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00021334060875233263;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[67], attr, VSI_NN_TYPE_INT32, 4182016, 1024);

    /* @254_102:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.006157001946121454;
    attr.dtype.zero_point = 158;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[68], attr, VSI_NN_TYPE_UINT8, 4545536, 65536);

    /* @254_102:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00014055441715754569;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[69], attr, VSI_NN_TYPE_INT32, 4545024, 512);

    /* @245_153:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007059021387249231;
    attr.dtype.zero_point = 150;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[70], attr, VSI_NN_TYPE_UINT8, 4314624, 65536);

    /* @245_153:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00016114607569761574;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[71], attr, VSI_NN_TYPE_INT32, 4314112, 512);

    /* @248_138:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.01219079177826643;
    attr.dtype.zero_point = 137;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[72], attr, VSI_NN_TYPE_UINT8, 4380672, 16384);

    /* @248_138:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00018255265604238957;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[73], attr, VSI_NN_TYPE_INT32, 4380160, 512);

    /* @251_111:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00470360554754734;
    attr.dtype.zero_point = 150;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[74], attr, VSI_NN_TYPE_UINT8, 4397568, 147456);

    /* @251_111:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 8.870977762853727e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[75], attr, VSI_NN_TYPE_INT32, 4397056, 512);

    /* @258_90:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.010936480015516281;
    attr.dtype.zero_point = 153;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[76], attr, VSI_NN_TYPE_UINT8, 4612096, 65536);

    /* @258_90:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00016649794997647405;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[77], attr, VSI_NN_TYPE_INT32, 4611072, 1024);

    /* @261_56:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.005018447060137987;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[78], attr, VSI_NN_TYPE_UINT8, 4678144, 32768);

    /* @261_56:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00011345538950990885;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[79], attr, VSI_NN_TYPE_INT32, 4677632, 512);

    /* @279_34:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0084502212703228;
    attr.dtype.zero_point = 170;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[80], attr, VSI_NN_TYPE_UINT8, 4769280, 16384);

    /* @279_34:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00017196925182361156;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[81], attr, VSI_NN_TYPE_INT32, 4769024, 256);

    /* @270_92:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.006469980347901583;
    attr.dtype.zero_point = 138;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[82], attr, VSI_NN_TYPE_UINT8, 4711168, 16384);

    /* @270_92:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00013166965800337493;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[83], attr, VSI_NN_TYPE_INT32, 4710912, 256);

    /* @273_75:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.013424075208604336;
    attr.dtype.zero_point = 153;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[84], attr, VSI_NN_TYPE_UINT8, 4727808, 4096);

    /* @273_75:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00013235665392130613;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[85], attr, VSI_NN_TYPE_INT32, 4727552, 256);

    /* @276_44:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 64;
    attr.size[3] = 64;
    attr.dim_num = 4;
    attr.dtype.scale = 0.010776573792099953;
    attr.dtype.zero_point = 150;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[86], attr, VSI_NN_TYPE_UINT8, 4732160, 36864);

    /* @276_44:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 64;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00011749496479751542;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[87], attr, VSI_NN_TYPE_INT32, 4731904, 256);

    /* @283_19:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.033583976328372955;
    attr.dtype.zero_point = 99;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[88], attr, VSI_NN_TYPE_UINT8, 4786176, 16384);

    /* @283_19:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0008165673934854567;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[89], attr, VSI_NN_TYPE_INT32, 4785664, 512);

    /* @326_11:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 255;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0037387025076895952;
    attr.dtype.zero_point = 140;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[90], attr, VSI_NN_TYPE_UINT8, 7026172, 32640);

    /* @326_11:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 255;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00019363532192073762;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[91], attr, VSI_NN_TYPE_INT32, 7025152, 1020);

    /* @286_71:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0018741065869107842;
    attr.dtype.zero_point = 106;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[92], attr, VSI_NN_TYPE_UINT8, 4803072, 147456);

    /* @286_71:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 9.706395212560892e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[93], attr, VSI_NN_TYPE_INT32, 4802560, 512);

    /* @299_31:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.009194305166602135;
    attr.dtype.zero_point = 156;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[94], attr, VSI_NN_TYPE_UINT8, 5149184, 32768);

    /* @299_31:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00018711200391408056;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[95], attr, VSI_NN_TYPE_INT32, 5148672, 512);

    /* @290_86:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007286927662789822;
    attr.dtype.zero_point = 147;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[96], attr, VSI_NN_TYPE_UINT8, 4951040, 32768);

    /* @290_86:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001482952357036993;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[97], attr, VSI_NN_TYPE_INT32, 4950528, 512);

    /* @293_69:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.00856582261621952;
    attr.dtype.zero_point = 149;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[98], attr, VSI_NN_TYPE_UINT8, 4984320, 16384);

    /* @293_69:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001511869631940499;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[99], attr, VSI_NN_TYPE_INT32, 4983808, 512);

    /* @296_40:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 128;
    attr.size[3] = 128;
    attr.dim_num = 4;
    attr.dtype.scale = 0.007501648738980293;
    attr.dtype.zero_point = 151;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[100], attr, VSI_NN_TYPE_UINT8, 5001216, 147456);

    /* @296_40:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 128;
    attr.dim_num = 1;
    attr.dtype.scale = 9.153845894616097e-05;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[101], attr, VSI_NN_TYPE_INT32, 5000704, 512);

    /* @303_17:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.017144285142421722;
    attr.dtype.zero_point = 121;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[102], attr, VSI_NN_TYPE_UINT8, 5182976, 65536);

    /* @303_17:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00039953214582055807;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[103], attr, VSI_NN_TYPE_INT32, 5181952, 1024);

    /* @474_10:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 255;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0034323299769312143;
    attr.dtype.zero_point = 122;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[104], attr, VSI_NN_TYPE_UINT8, 7059832, 65280);

    /* @474_10:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 255;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0001897194451885298;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[105], attr, VSI_NN_TYPE_INT32, 7058812, 1020);

    /* @306_65:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.002137536648660898;
    attr.dtype.zero_point = 105;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[106], attr, VSI_NN_TYPE_UINT8, 5249536, 589824);

    /* @306_65:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00011815072502940893;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[107], attr, VSI_NN_TYPE_INT32, 5248512, 1024);

    /* @319_28:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.006345307920128107;
    attr.dtype.zero_point = 147;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[108], attr, VSI_NN_TYPE_UINT8, 6629888, 131072);

    /* @319_28:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00014485314022749662;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[109], attr, VSI_NN_TYPE_INT32, 6628864, 1024);

    /* @310_80:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.011167038232088089;
    attr.dtype.zero_point = 150;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[110], attr, VSI_NN_TYPE_UINT8, 5840384, 131072);

    /* @310_80:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002549254859331995;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[111], attr, VSI_NN_TYPE_INT32, 5839360, 1024);

    /* @313_63:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.009258603677153587;
    attr.dtype.zero_point = 165;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[112], attr, VSI_NN_TYPE_UINT8, 5972480, 65536);

    /* @313_63:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.0002975498791784048;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[113], attr, VSI_NN_TYPE_INT32, 5971456, 1024);

    /* @316_36:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 3;
    attr.size[1] = 3;
    attr.size[2] = 256;
    attr.size[3] = 256;
    attr.dim_num = 4;
    attr.dtype.scale = 0.005748922470957041;
    attr.dtype.zero_point = 140;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[114], attr, VSI_NN_TYPE_UINT8, 6039040, 589824);

    /* @316_36:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 256;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00014046225987840444;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[115], attr, VSI_NN_TYPE_INT32, 6038016, 1024);

    /* @323_15:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 512;
    attr.dim_num = 4;
    attr.dtype.scale = 0.009458360262215137;
    attr.dtype.zero_point = 138;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[116], attr, VSI_NN_TYPE_UINT8, 6763008, 262144);

    /* @323_15:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 512;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00032522116089239717;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[117], attr, VSI_NN_TYPE_INT32, 6760960, 2048);

    /* @622_9:weight */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 1;
    attr.size[1] = 1;
    attr.size[2] = 512;
    attr.size[3] = 255;
    attr.dim_num = 4;
    attr.dtype.scale = 0.0029813877772539854;
    attr.dtype.zero_point = 115;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[118], attr, VSI_NN_TYPE_UINT8, 7126132, 130560);

    /* @622_9:bias */
    memset( &attr, 0, sizeof( attr ) );
    attr.size[0] = 255;
    attr.dim_num = 1;
    attr.dtype.scale = 0.00013700118870474398;
    attr.dtype.zero_point = 0;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_CONST_TENSOR(const_tensor[119], attr, VSI_NN_TYPE_INT32, 7125112, 1020);



    /* @122_193:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.3532538115978241;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[0]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @123_194_124_178:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.16159670054912567;
    attr.dtype.zero_point = 2;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[1]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @125_177:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.5307658910751343;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[2]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @126_163_127_162:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.23036719858646393;
    attr.dtype.zero_point = 1;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[3]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @138_148:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.3109690845012665;
    attr.dtype.zero_point = 179;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[4]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @128_173:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.2229774445295334;
    attr.dtype.zero_point = 231;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[5]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @139_149_140_135:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.08328528702259064;
    attr.dtype.zero_point = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[6]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @129_174_130_160:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.01657266914844513;
    attr.dtype.zero_point = 17;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[7]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @131_195:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.17855684459209442;
    attr.dtype.zero_point = 159;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[8]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @132_192_133_191:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.05588525906205177;
    attr.dtype.zero_point = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[9]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @134_175:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.108803890645504;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[10]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @135_176_136_161:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.050917357206344604;
    attr.dtype.zero_point = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[11]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @137_147:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.08328528702259064;
    attr.dtype.zero_point = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[12]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @141_134:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.08328528702259064;
    attr.dtype.zero_point = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[13]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @142_119:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.09686309099197388;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[14]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @143_120_144_109:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04970211535692215;
    attr.dtype.zero_point = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[15]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @145_107:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06232142820954323;
    attr.dtype.zero_point = 155;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[16]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @146_108_147_96:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022463181987404823;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[17]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @165_83:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04889460653066635;
    attr.dtype.zero_point = 138;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[18]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @148_128:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02753002569079399;
    attr.dtype.zero_point = 175;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[19]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @166_82_167_79:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02947213128209114;
    attr.dtype.zero_point = 28;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[20]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @149_129_150_115:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.00838521122932434;
    attr.dtype.zero_point = 33;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[21]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @151_145:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04967069998383522;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[22]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @152_146_153_133:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.024008065462112427;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[23]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @154_130:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.033445607870817184;
    attr.dtype.zero_point = 150;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[24]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @155_131_156_116:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.013631903566420078;
    attr.dtype.zero_point = 20;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[25]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @157_104:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.013228545896708965;
    attr.dtype.zero_point = 42;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[26]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @158_132:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04507302865386009;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[27]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @159_118_160_117:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022124461829662323;
    attr.dtype.zero_point = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[28]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @161_105:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06261014193296432;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[29]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @162_106_163_95:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02706168219447136;
    attr.dtype.zero_point = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[30]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @164_94:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02947213128209114;
    attr.dtype.zero_point = 28;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[31]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @168_78:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02947213128209114;
    attr.dtype.zero_point = 28;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[32]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @169_61:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.05216096341609955;
    attr.dtype.zero_point = 129;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[33]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @170_62_171_47:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.020350858569145203;
    attr.dtype.zero_point = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[34]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @172_159:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04972347989678383;
    attr.dtype.zero_point = 133;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[35]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @173_158_174_157:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.020350230857729912;
    attr.dtype.zero_point = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[36]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @199_144:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06209916993975639;
    attr.dtype.zero_point = 110;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[37]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @175_204:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.027225971221923828;
    attr.dtype.zero_point = 181;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[38]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @200_143_201_142:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03965119644999504;
    attr.dtype.zero_point = 28;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[39]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @176_205_177_199:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.008090585470199585;
    attr.dtype.zero_point = 34;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[40]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @178_207:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04900091513991356;
    attr.dtype.zero_point = 128;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[41]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @179_206_180_203:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02382487617433071;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[42]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @181_202:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.030807945877313614;
    attr.dtype.zero_point = 158;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[43]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @182_201_183_200:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.011615557596087456;
    attr.dtype.zero_point = 24;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[44]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @184_185:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.01332067046314478;
    attr.dtype.zero_point = 42;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[45]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @185_198:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04655303806066513;
    attr.dtype.zero_point = 133;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[46]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @186_196_187_190:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023366836830973625;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[47]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @188_189:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.0454367995262146;
    attr.dtype.zero_point = 131;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[48]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @189_188_190_186:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023126723244786263;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[49]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @191_168:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.024432407692074776;
    attr.dtype.zero_point = 34;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[50]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @192_187:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04688037931919098;
    attr.dtype.zero_point = 137;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[51]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @193_172_194_171:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022707711905241013;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[52]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @195_169:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.058811772614717484;
    attr.dtype.zero_point = 137;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[53]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @196_170_197_156:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.028394151479005814;
    attr.dtype.zero_point = 10;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[54]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @198_155:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03965119644999504;
    attr.dtype.zero_point = 28;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[55]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @202_141:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03965119644999504;
    attr.dtype.zero_point = 28;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[56]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @203_126:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.049403078854084015;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[57]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @204_127_205_114:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02282838709652424;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[58]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @206_166:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.05652857944369316;
    attr.dtype.zero_point = 144;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[59]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @207_167_208_154:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.024115663021802902;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[60]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @219_151:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.054992031306028366;
    attr.dtype.zero_point = 149;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[61]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @209_179:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04099542275071144;
    attr.dtype.zero_point = 119;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[62]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @220_152_221_137:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03557993844151497;
    attr.dtype.zero_point = 16;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[63]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @210_180_211_164:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022824754938483238;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[64]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @212_197:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06973326951265335;
    attr.dtype.zero_point = 121;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[65]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @213_184_214_183:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03785069286823273;
    attr.dtype.zero_point = 7;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[66]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @215_181:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06573496758937836;
    attr.dtype.zero_point = 138;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[67]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @216_182_217_165:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.031116200610995293;
    attr.dtype.zero_point = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[68]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @218_150:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03557993844151497;
    attr.dtype.zero_point = 16;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[69]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @222_136:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03557993844151497;
    attr.dtype.zero_point = 16;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[70]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @223_121:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.050429992377758026;
    attr.dtype.zero_point = 153;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[71]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @224_122_225_110:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02107575535774231;
    attr.dtype.zero_point = 13;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[72]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @226_100:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03403526544570923;
    attr.dtype.zero_point = 92;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[73]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @227_99_228_97:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022800171747803688;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[74]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @229_98:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022800171747803688;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[75]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @230_89:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022800171747803688;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[76]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @231_88:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022800171747803688;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[77]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @232_85:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022800171747803688;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[78]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @233_84:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04236767068505287;
    attr.dtype.zero_point = 138;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[79]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @234_68_235_67:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.020331205800175667;
    attr.dtype.zero_point = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[80]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @236_51:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04614339396357536;
    attr.dtype.zero_point = 134;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[81]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @237_52_238_39:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02282838709652424;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[82]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @243_125:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02282838709652424;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[83]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @244_113:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02282838709652424;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[84]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @254_102:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.034822992980480194;
    attr.dtype.zero_point = 160;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[85]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @245_153:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.036015573889017105;
    attr.dtype.zero_point = 154;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[86]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @255_103_256_93:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.015224088914692402;
    attr.dtype.zero_point = 18;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[87]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @246_140_247_139:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.01497463509440422;
    attr.dtype.zero_point = 19;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[88]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @248_138:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04116189107298851;
    attr.dtype.zero_point = 144;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[89]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @249_124_250_123:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.018859952688217163;
    attr.dtype.zero_point = 15;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[90]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @251_111:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03297712281346321;
    attr.dtype.zero_point = 143;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[91]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @252_112_253_101:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.015224088914692402;
    attr.dtype.zero_point = 18;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[92]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @257_91:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.015224088914692402;
    attr.dtype.zero_point = 18;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[93]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @258_90:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04456672444939613;
    attr.dtype.zero_point = 131;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[94]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @259_74_260_73:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.022607669234275818;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[95]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @261_56:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.029283685609698296;
    attr.dtype.zero_point = 129;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[96]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @262_57_263_43:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.020350858569145203;
    attr.dtype.zero_point = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[97]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @268_60:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.020350858569145203;
    attr.dtype.zero_point = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[98]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @269_46:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.020350858569145203;
    attr.dtype.zero_point = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[99]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @279_34:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03737325593829155;
    attr.dtype.zero_point = 154;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[100]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @270_92:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.027964459732174873;
    attr.dtype.zero_point = 144;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[101]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @280_35_281_26:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.024314196780323982;
    attr.dtype.zero_point = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[102]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @271_77_272_76:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.00985964760184288;
    attr.dtype.zero_point = 28;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[103]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @273_75:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02886945568025112;
    attr.dtype.zero_point = 162;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[104]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @274_59_275_58:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.010902812704443932;
    attr.dtype.zero_point = 26;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[105]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @276_44:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04943152144551277;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[106]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @277_45_278_33:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.024314196780323982;
    attr.dtype.zero_point = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[107]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @282_25:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.024314196780323982;
    attr.dtype.zero_point = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[108]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @283_19:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.10970418155193329;
    attr.dtype.zero_point = 129;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[109]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @284_20_285_14:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.051792118698358536;
    attr.dtype.zero_point = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[110]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @326_11:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.08591902256011963;
    attr.dtype.zero_point = 211;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[111]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @286_71:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.035780660808086395;
    attr.dtype.zero_point = 130;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[112]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @349_8:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.08591902256011963;
    attr.dtype.zero_point = 211;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[113]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @287_72_288_55:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.020350858569145203;
    attr.dtype.zero_point = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[114]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @289_42:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.020350858569145203;
    attr.dtype.zero_point = 14;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[116]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @299_31:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03833433613181114;
    attr.dtype.zero_point = 125;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[117]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @290_86:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03579211235046387;
    attr.dtype.zero_point = 135;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[118]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @300_32_301_24:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023304101079702377;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[119]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @291_87_292_70:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.017650023102760315;
    attr.dtype.zero_point = 16;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[120]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @293_69:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03430233523249626;
    attr.dtype.zero_point = 151;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[121]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @294_54_295_53:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.012202445417642593;
    attr.dtype.zero_point = 23;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[122]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @296_40:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.05053287371993065;
    attr.dtype.zero_point = 143;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[123]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @297_41_298_30:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023304101079702377;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[124]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @302_23:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.023304101079702377;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[125]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @303_17:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.10111052542924881;
    attr.dtype.zero_point = 127;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[126]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @304_18_305_13:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.05527424439787865;
    attr.dtype.zero_point = 5;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[127]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @474_10:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.07161629945039749;
    attr.dtype.zero_point = 204;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[128]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @306_65:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04073062911629677;
    attr.dtype.zero_point = 138;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[129]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @497_7:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.07161629945039749;
    attr.dtype.zero_point = 204;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[130]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @307_66_308_50:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02282838709652424;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[131]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @309_38:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.02282838709652424;
    attr.dtype.zero_point = 12;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[133]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @319_28:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.044258181005716324;
    attr.dtype.zero_point = 123;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[134]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @310_80:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.06134651228785515;
    attr.dtype.zero_point = 126;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[135]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @320_29_321_22:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03438451886177063;
    attr.dtype.zero_point = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[136]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @311_81_312_64:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.032137662172317505;
    attr.dtype.zero_point = 9;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[137]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @313_63:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.055543478578329086;
    attr.dtype.zero_point = 148;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[138]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @314_49_315_48:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.024432798847556114;
    attr.dtype.zero_point = 11;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[139]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @316_36:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.09447306394577026;
    attr.dtype.zero_point = 165;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[140]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @317_37_318_27:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03438451886177063;
    attr.dtype.zero_point = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[141]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @322_21:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.03438451886177063;
    attr.dtype.zero_point = 8;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[142]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @323_15:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.08067511767148972;
    attr.dtype.zero_point = 113;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[143]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @324_16_325_12:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.04595215246081352;
    attr.dtype.zero_point = 6;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[144]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @622_9:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.07200625538825989;
    attr.dtype.zero_point = 196;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[145]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);

    /* @645_6:out0 */
    memset( &attr, 0, sizeof( attr ) );
    attr.dtype.scale = 0.07200625538825989;
    attr.dtype.zero_point = 196;
    attr.dtype.qnt_type = VSI_NN_QNT_TYPE_AFFINE_ASYMMETRIC;
    NEW_VIRTUAL_TENSOR(node[146]->output.tensors[0], attr, VSI_NN_TYPE_UINT8);



/*-----------------------------------------
  Connection initialize
 -----------------------------------------*/
    node[0]->input.tensors[0] = norm_tensor[3];
    node[115]->output.tensors[0] = norm_tensor[0];
    node[132]->output.tensors[0] = norm_tensor[1];
    node[147]->output.tensors[0] = norm_tensor[2];

    /* 122_193 */
    node[0]->input.tensors[1] = const_tensor[0]; /* data_weight */
    node[0]->input.tensors[2] = const_tensor[1]; /* data_bias */

    /* 123_194_124_178 */
    node[1]->input.tensors[0] = node[0]->output.tensors[0];

    /* 125_177 */
    node[2]->input.tensors[0] = node[1]->output.tensors[0];
    node[2]->input.tensors[1] = const_tensor[2]; /* data_weight */
    node[2]->input.tensors[2] = const_tensor[3]; /* data_bias */

    /* 126_163_127_162 */
    node[3]->input.tensors[0] = node[2]->output.tensors[0];

    /* 138_148 */
    node[4]->input.tensors[0] = node[3]->output.tensors[0];
    node[4]->input.tensors[1] = const_tensor[4]; /* data_weight */
    node[4]->input.tensors[2] = const_tensor[5]; /* data_bias */

    /* 128_173 */
    node[5]->input.tensors[0] = node[3]->output.tensors[0];
    node[5]->input.tensors[1] = const_tensor[6]; /* data_weight */
    node[5]->input.tensors[2] = const_tensor[7]; /* data_bias */

    /* 139_149_140_135 */
    node[6]->input.tensors[0] = node[4]->output.tensors[0];

    /* 129_174_130_160 */
    node[7]->input.tensors[0] = node[5]->output.tensors[0];

    /* 131_195 */
    node[8]->input.tensors[0] = node[7]->output.tensors[0];
    node[8]->input.tensors[1] = const_tensor[8]; /* data_weight */
    node[8]->input.tensors[2] = const_tensor[9]; /* data_bias */

    /* 132_192_133_191 */
    node[9]->input.tensors[0] = node[8]->output.tensors[0];

    /* 134_175 */
    node[10]->input.tensors[0] = node[9]->output.tensors[0];
    node[10]->input.tensors[1] = const_tensor[10]; /* data_weight */
    node[10]->input.tensors[2] = const_tensor[11]; /* data_bias */

    /* 135_176_136_161 */
    node[11]->input.tensors[0] = node[10]->output.tensors[0];

    /* 137_147 */
    node[12]->input.tensors[0] = node[7]->output.tensors[0];
    node[12]->input.tensors[1] = node[11]->output.tensors[0];

    /* 141_134 */
    node[13]->input.tensors[0] = node[12]->output.tensors[0];
    node[13]->input.tensors[1] = node[6]->output.tensors[0];

    /* 142_119 */
    node[14]->input.tensors[0] = node[13]->output.tensors[0];
    node[14]->input.tensors[1] = const_tensor[12]; /* data_weight */
    node[14]->input.tensors[2] = const_tensor[13]; /* data_bias */

    /* 143_120_144_109 */
    node[15]->input.tensors[0] = node[14]->output.tensors[0];

    /* 145_107 */
    node[16]->input.tensors[0] = node[15]->output.tensors[0];
    node[16]->input.tensors[1] = const_tensor[14]; /* data_weight */
    node[16]->input.tensors[2] = const_tensor[15]; /* data_bias */

    /* 146_108_147_96 */
    node[17]->input.tensors[0] = node[16]->output.tensors[0];

    /* 165_83 */
    node[18]->input.tensors[0] = node[17]->output.tensors[0];
    node[18]->input.tensors[1] = const_tensor[16]; /* data_weight */
    node[18]->input.tensors[2] = const_tensor[17]; /* data_bias */

    /* 148_128 */
    node[19]->input.tensors[0] = node[17]->output.tensors[0];
    node[19]->input.tensors[1] = const_tensor[18]; /* data_weight */
    node[19]->input.tensors[2] = const_tensor[19]; /* data_bias */

    /* 166_82_167_79 */
    node[20]->input.tensors[0] = node[18]->output.tensors[0];

    /* 149_129_150_115 */
    node[21]->input.tensors[0] = node[19]->output.tensors[0];

    /* 151_145 */
    node[22]->input.tensors[0] = node[21]->output.tensors[0];
    node[22]->input.tensors[1] = const_tensor[20]; /* data_weight */
    node[22]->input.tensors[2] = const_tensor[21]; /* data_bias */

    /* 152_146_153_133 */
    node[23]->input.tensors[0] = node[22]->output.tensors[0];

    /* 154_130 */
    node[24]->input.tensors[0] = node[23]->output.tensors[0];
    node[24]->input.tensors[1] = const_tensor[22]; /* data_weight */
    node[24]->input.tensors[2] = const_tensor[23]; /* data_bias */

    /* 155_131_156_116 */
    node[25]->input.tensors[0] = node[24]->output.tensors[0];

    /* 157_104 */
    node[26]->input.tensors[0] = node[21]->output.tensors[0];
    node[26]->input.tensors[1] = node[25]->output.tensors[0];

    /* 158_132 */
    node[27]->input.tensors[0] = node[26]->output.tensors[0];
    node[27]->input.tensors[1] = const_tensor[24]; /* data_weight */
    node[27]->input.tensors[2] = const_tensor[25]; /* data_bias */

    /* 159_118_160_117 */
    node[28]->input.tensors[0] = node[27]->output.tensors[0];

    /* 161_105 */
    node[29]->input.tensors[0] = node[28]->output.tensors[0];
    node[29]->input.tensors[1] = const_tensor[26]; /* data_weight */
    node[29]->input.tensors[2] = const_tensor[27]; /* data_bias */

    /* 162_106_163_95 */
    node[30]->input.tensors[0] = node[29]->output.tensors[0];

    /* 164_94 */
    node[31]->input.tensors[0] = node[26]->output.tensors[0];
    node[31]->input.tensors[1] = node[30]->output.tensors[0];

    /* 168_78 */
    node[32]->input.tensors[0] = node[31]->output.tensors[0];
    node[32]->input.tensors[1] = node[20]->output.tensors[0];

    /* 169_61 */
    node[33]->input.tensors[0] = node[32]->output.tensors[0];
    node[33]->input.tensors[1] = const_tensor[28]; /* data_weight */
    node[33]->input.tensors[2] = const_tensor[29]; /* data_bias */

    /* 170_62_171_47 */
    node[34]->input.tensors[0] = node[33]->output.tensors[0];

    /* 172_159 */
    node[35]->input.tensors[0] = node[34]->output.tensors[0];
    node[35]->input.tensors[1] = const_tensor[30]; /* data_weight */
    node[35]->input.tensors[2] = const_tensor[31]; /* data_bias */

    /* 173_158_174_157 */
    node[36]->input.tensors[0] = node[35]->output.tensors[0];

    /* 199_144 */
    node[37]->input.tensors[0] = node[36]->output.tensors[0];
    node[37]->input.tensors[1] = const_tensor[32]; /* data_weight */
    node[37]->input.tensors[2] = const_tensor[33]; /* data_bias */

    /* 175_204 */
    node[38]->input.tensors[0] = node[36]->output.tensors[0];
    node[38]->input.tensors[1] = const_tensor[34]; /* data_weight */
    node[38]->input.tensors[2] = const_tensor[35]; /* data_bias */

    /* 200_143_201_142 */
    node[39]->input.tensors[0] = node[37]->output.tensors[0];

    /* 176_205_177_199 */
    node[40]->input.tensors[0] = node[38]->output.tensors[0];

    /* 178_207 */
    node[41]->input.tensors[0] = node[40]->output.tensors[0];
    node[41]->input.tensors[1] = const_tensor[36]; /* data_weight */
    node[41]->input.tensors[2] = const_tensor[37]; /* data_bias */

    /* 179_206_180_203 */
    node[42]->input.tensors[0] = node[41]->output.tensors[0];

    /* 181_202 */
    node[43]->input.tensors[0] = node[42]->output.tensors[0];
    node[43]->input.tensors[1] = const_tensor[38]; /* data_weight */
    node[43]->input.tensors[2] = const_tensor[39]; /* data_bias */

    /* 182_201_183_200 */
    node[44]->input.tensors[0] = node[43]->output.tensors[0];

    /* 184_185 */
    node[45]->input.tensors[0] = node[40]->output.tensors[0];
    node[45]->input.tensors[1] = node[44]->output.tensors[0];

    /* 185_198 */
    node[46]->input.tensors[0] = node[45]->output.tensors[0];
    node[46]->input.tensors[1] = const_tensor[40]; /* data_weight */
    node[46]->input.tensors[2] = const_tensor[41]; /* data_bias */

    /* 186_196_187_190 */
    node[47]->input.tensors[0] = node[46]->output.tensors[0];

    /* 188_189 */
    node[48]->input.tensors[0] = node[47]->output.tensors[0];
    node[48]->input.tensors[1] = const_tensor[42]; /* data_weight */
    node[48]->input.tensors[2] = const_tensor[43]; /* data_bias */

    /* 189_188_190_186 */
    node[49]->input.tensors[0] = node[48]->output.tensors[0];

    /* 191_168 */
    node[50]->input.tensors[0] = node[45]->output.tensors[0];
    node[50]->input.tensors[1] = node[49]->output.tensors[0];

    /* 192_187 */
    node[51]->input.tensors[0] = node[50]->output.tensors[0];
    node[51]->input.tensors[1] = const_tensor[44]; /* data_weight */
    node[51]->input.tensors[2] = const_tensor[45]; /* data_bias */

    /* 193_172_194_171 */
    node[52]->input.tensors[0] = node[51]->output.tensors[0];

    /* 195_169 */
    node[53]->input.tensors[0] = node[52]->output.tensors[0];
    node[53]->input.tensors[1] = const_tensor[46]; /* data_weight */
    node[53]->input.tensors[2] = const_tensor[47]; /* data_bias */

    /* 196_170_197_156 */
    node[54]->input.tensors[0] = node[53]->output.tensors[0];

    /* 198_155 */
    node[55]->input.tensors[0] = node[50]->output.tensors[0];
    node[55]->input.tensors[1] = node[54]->output.tensors[0];

    /* 202_141 */
    node[56]->input.tensors[0] = node[55]->output.tensors[0];
    node[56]->input.tensors[1] = node[39]->output.tensors[0];

    /* 203_126 */
    node[57]->input.tensors[0] = node[56]->output.tensors[0];
    node[57]->input.tensors[1] = const_tensor[48]; /* data_weight */
    node[57]->input.tensors[2] = const_tensor[49]; /* data_bias */

    /* 204_127_205_114 */
    node[58]->input.tensors[0] = node[57]->output.tensors[0];

    /* 206_166 */
    node[59]->input.tensors[0] = node[58]->output.tensors[0];
    node[59]->input.tensors[1] = const_tensor[50]; /* data_weight */
    node[59]->input.tensors[2] = const_tensor[51]; /* data_bias */

    /* 207_167_208_154 */
    node[60]->input.tensors[0] = node[59]->output.tensors[0];

    /* 219_151 */
    node[61]->input.tensors[0] = node[60]->output.tensors[0];
    node[61]->input.tensors[1] = const_tensor[52]; /* data_weight */
    node[61]->input.tensors[2] = const_tensor[53]; /* data_bias */

    /* 209_179 */
    node[62]->input.tensors[0] = node[60]->output.tensors[0];
    node[62]->input.tensors[1] = const_tensor[54]; /* data_weight */
    node[62]->input.tensors[2] = const_tensor[55]; /* data_bias */

    /* 220_152_221_137 */
    node[63]->input.tensors[0] = node[61]->output.tensors[0];

    /* 210_180_211_164 */
    node[64]->input.tensors[0] = node[62]->output.tensors[0];

    /* 212_197 */
    node[65]->input.tensors[0] = node[64]->output.tensors[0];
    node[65]->input.tensors[1] = const_tensor[56]; /* data_weight */
    node[65]->input.tensors[2] = const_tensor[57]; /* data_bias */

    /* 213_184_214_183 */
    node[66]->input.tensors[0] = node[65]->output.tensors[0];

    /* 215_181 */
    node[67]->input.tensors[0] = node[66]->output.tensors[0];
    node[67]->input.tensors[1] = const_tensor[58]; /* data_weight */
    node[67]->input.tensors[2] = const_tensor[59]; /* data_bias */

    /* 216_182_217_165 */
    node[68]->input.tensors[0] = node[67]->output.tensors[0];

    /* 218_150 */
    node[69]->input.tensors[0] = node[64]->output.tensors[0];
    node[69]->input.tensors[1] = node[68]->output.tensors[0];

    /* 222_136 */
    node[70]->input.tensors[0] = node[69]->output.tensors[0];
    node[70]->input.tensors[1] = node[63]->output.tensors[0];

    /* 223_121 */
    node[71]->input.tensors[0] = node[70]->output.tensors[0];
    node[71]->input.tensors[1] = const_tensor[60]; /* data_weight */
    node[71]->input.tensors[2] = const_tensor[61]; /* data_bias */

    /* 224_122_225_110 */
    node[72]->input.tensors[0] = node[71]->output.tensors[0];

    /* 226_100 */
    node[73]->input.tensors[0] = node[72]->output.tensors[0];
    node[73]->input.tensors[1] = const_tensor[62]; /* data_weight */
    node[73]->input.tensors[2] = const_tensor[63]; /* data_bias */

    /* 227_99_228_97 */
    node[74]->input.tensors[0] = node[73]->output.tensors[0];

    /* 229_98 */
    node[75]->input.tensors[0] = node[74]->output.tensors[0];

    /* 230_89 */
    node[76]->input.tensors[0] = node[75]->output.tensors[0];

    /* 231_88 */
    node[77]->input.tensors[0] = node[76]->output.tensors[0];

    /* 232_85 */
    node[78]->input.tensors[0] = node[74]->output.tensors[0];
    node[78]->input.tensors[1] = node[75]->output.tensors[0];
    node[78]->input.tensors[2] = node[76]->output.tensors[0];
    node[78]->input.tensors[3] = node[77]->output.tensors[0];

    /* 233_84 */
    node[79]->input.tensors[0] = node[78]->output.tensors[0];
    node[79]->input.tensors[1] = const_tensor[64]; /* data_weight */
    node[79]->input.tensors[2] = const_tensor[65]; /* data_bias */

    /* 234_68_235_67 */
    node[80]->input.tensors[0] = node[79]->output.tensors[0];

    /* 236_51 */
    node[81]->input.tensors[0] = node[80]->output.tensors[0];
    node[81]->input.tensors[1] = const_tensor[66]; /* data_weight */
    node[81]->input.tensors[2] = const_tensor[67]; /* data_bias */

    /* 237_52_238_39 */
    node[82]->input.tensors[0] = node[81]->output.tensors[0];

    /* 243_125 */
    node[83]->input.tensors[0] = node[82]->output.tensors[0];

    /* 244_113 */
    node[84]->input.tensors[0] = node[83]->output.tensors[0];
    node[84]->input.tensors[1] = node[58]->output.tensors[0];

    /* 254_102 */
    node[85]->input.tensors[0] = node[84]->output.tensors[0];
    node[85]->input.tensors[1] = const_tensor[68]; /* data_weight */
    node[85]->input.tensors[2] = const_tensor[69]; /* data_bias */

    /* 245_153 */
    node[86]->input.tensors[0] = node[84]->output.tensors[0];
    node[86]->input.tensors[1] = const_tensor[70]; /* data_weight */
    node[86]->input.tensors[2] = const_tensor[71]; /* data_bias */

    /* 255_103_256_93 */
    node[87]->input.tensors[0] = node[85]->output.tensors[0];

    /* 246_140_247_139 */
    node[88]->input.tensors[0] = node[86]->output.tensors[0];

    /* 248_138 */
    node[89]->input.tensors[0] = node[88]->output.tensors[0];
    node[89]->input.tensors[1] = const_tensor[72]; /* data_weight */
    node[89]->input.tensors[2] = const_tensor[73]; /* data_bias */

    /* 249_124_250_123 */
    node[90]->input.tensors[0] = node[89]->output.tensors[0];

    /* 251_111 */
    node[91]->input.tensors[0] = node[90]->output.tensors[0];
    node[91]->input.tensors[1] = const_tensor[74]; /* data_weight */
    node[91]->input.tensors[2] = const_tensor[75]; /* data_bias */

    /* 252_112_253_101 */
    node[92]->input.tensors[0] = node[91]->output.tensors[0];

    /* 257_91 */
    node[93]->input.tensors[0] = node[92]->output.tensors[0];
    node[93]->input.tensors[1] = node[87]->output.tensors[0];

    /* 258_90 */
    node[94]->input.tensors[0] = node[93]->output.tensors[0];
    node[94]->input.tensors[1] = const_tensor[76]; /* data_weight */
    node[94]->input.tensors[2] = const_tensor[77]; /* data_bias */

    /* 259_74_260_73 */
    node[95]->input.tensors[0] = node[94]->output.tensors[0];

    /* 261_56 */
    node[96]->input.tensors[0] = node[95]->output.tensors[0];
    node[96]->input.tensors[1] = const_tensor[78]; /* data_weight */
    node[96]->input.tensors[2] = const_tensor[79]; /* data_bias */

    /* 262_57_263_43 */
    node[97]->input.tensors[0] = node[96]->output.tensors[0];

    /* 268_60 */
    node[98]->input.tensors[0] = node[97]->output.tensors[0];

    /* 269_46 */
    node[99]->input.tensors[0] = node[98]->output.tensors[0];
    node[99]->input.tensors[1] = node[34]->output.tensors[0];

    /* 279_34 */
    node[100]->input.tensors[0] = node[99]->output.tensors[0];
    node[100]->input.tensors[1] = const_tensor[80]; /* data_weight */
    node[100]->input.tensors[2] = const_tensor[81]; /* data_bias */

    /* 270_92 */
    node[101]->input.tensors[0] = node[99]->output.tensors[0];
    node[101]->input.tensors[1] = const_tensor[82]; /* data_weight */
    node[101]->input.tensors[2] = const_tensor[83]; /* data_bias */

    /* 280_35_281_26 */
    node[102]->input.tensors[0] = node[100]->output.tensors[0];

    /* 271_77_272_76 */
    node[103]->input.tensors[0] = node[101]->output.tensors[0];

    /* 273_75 */
    node[104]->input.tensors[0] = node[103]->output.tensors[0];
    node[104]->input.tensors[1] = const_tensor[84]; /* data_weight */
    node[104]->input.tensors[2] = const_tensor[85]; /* data_bias */

    /* 274_59_275_58 */
    node[105]->input.tensors[0] = node[104]->output.tensors[0];

    /* 276_44 */
    node[106]->input.tensors[0] = node[105]->output.tensors[0];
    node[106]->input.tensors[1] = const_tensor[86]; /* data_weight */
    node[106]->input.tensors[2] = const_tensor[87]; /* data_bias */

    /* 277_45_278_33 */
    node[107]->input.tensors[0] = node[106]->output.tensors[0];

    /* 282_25 */
    node[108]->input.tensors[0] = node[107]->output.tensors[0];
    node[108]->input.tensors[1] = node[102]->output.tensors[0];

    /* 283_19 */
    node[109]->input.tensors[0] = node[108]->output.tensors[0];
    node[109]->input.tensors[1] = const_tensor[88]; /* data_weight */
    node[109]->input.tensors[2] = const_tensor[89]; /* data_bias */

    /* 284_20_285_14 */
    node[110]->input.tensors[0] = node[109]->output.tensors[0];

    /* 326_11 */
    node[111]->input.tensors[0] = node[110]->output.tensors[0];
    node[111]->input.tensors[1] = const_tensor[90]; /* data_weight */
    node[111]->input.tensors[2] = const_tensor[91]; /* data_bias */

    /* 286_71 */
    node[112]->input.tensors[0] = node[110]->output.tensors[0];
    node[112]->input.tensors[1] = const_tensor[92]; /* data_weight */
    node[112]->input.tensors[2] = const_tensor[93]; /* data_bias */

    /* 349_8 */
    node[113]->input.tensors[0] = node[111]->output.tensors[0];

    /* 287_72_288_55 */
    node[114]->input.tensors[0] = node[112]->output.tensors[0];

    /* 350_5 */
    node[115]->input.tensors[0] = node[113]->output.tensors[0];

    /* 289_42 */
    node[116]->input.tensors[0] = node[114]->output.tensors[0];
    node[116]->input.tensors[1] = node[97]->output.tensors[0];

    /* 299_31 */
    node[117]->input.tensors[0] = node[116]->output.tensors[0];
    node[117]->input.tensors[1] = const_tensor[94]; /* data_weight */
    node[117]->input.tensors[2] = const_tensor[95]; /* data_bias */

    /* 290_86 */
    node[118]->input.tensors[0] = node[116]->output.tensors[0];
    node[118]->input.tensors[1] = const_tensor[96]; /* data_weight */
    node[118]->input.tensors[2] = const_tensor[97]; /* data_bias */

    /* 300_32_301_24 */
    node[119]->input.tensors[0] = node[117]->output.tensors[0];

    /* 291_87_292_70 */
    node[120]->input.tensors[0] = node[118]->output.tensors[0];

    /* 293_69 */
    node[121]->input.tensors[0] = node[120]->output.tensors[0];
    node[121]->input.tensors[1] = const_tensor[98]; /* data_weight */
    node[121]->input.tensors[2] = const_tensor[99]; /* data_bias */

    /* 294_54_295_53 */
    node[122]->input.tensors[0] = node[121]->output.tensors[0];

    /* 296_40 */
    node[123]->input.tensors[0] = node[122]->output.tensors[0];
    node[123]->input.tensors[1] = const_tensor[100]; /* data_weight */
    node[123]->input.tensors[2] = const_tensor[101]; /* data_bias */

    /* 297_41_298_30 */
    node[124]->input.tensors[0] = node[123]->output.tensors[0];

    /* 302_23 */
    node[125]->input.tensors[0] = node[124]->output.tensors[0];
    node[125]->input.tensors[1] = node[119]->output.tensors[0];

    /* 303_17 */
    node[126]->input.tensors[0] = node[125]->output.tensors[0];
    node[126]->input.tensors[1] = const_tensor[102]; /* data_weight */
    node[126]->input.tensors[2] = const_tensor[103]; /* data_bias */

    /* 304_18_305_13 */
    node[127]->input.tensors[0] = node[126]->output.tensors[0];

    /* 474_10 */
    node[128]->input.tensors[0] = node[127]->output.tensors[0];
    node[128]->input.tensors[1] = const_tensor[104]; /* data_weight */
    node[128]->input.tensors[2] = const_tensor[105]; /* data_bias */

    /* 306_65 */
    node[129]->input.tensors[0] = node[127]->output.tensors[0];
    node[129]->input.tensors[1] = const_tensor[106]; /* data_weight */
    node[129]->input.tensors[2] = const_tensor[107]; /* data_bias */

    /* 497_7 */
    node[130]->input.tensors[0] = node[128]->output.tensors[0];

    /* 307_66_308_50 */
    node[131]->input.tensors[0] = node[129]->output.tensors[0];

    /* 498_4 */
    node[132]->input.tensors[0] = node[130]->output.tensors[0];

    /* 309_38 */
    node[133]->input.tensors[0] = node[131]->output.tensors[0];
    node[133]->input.tensors[1] = node[82]->output.tensors[0];

    /* 319_28 */
    node[134]->input.tensors[0] = node[133]->output.tensors[0];
    node[134]->input.tensors[1] = const_tensor[108]; /* data_weight */
    node[134]->input.tensors[2] = const_tensor[109]; /* data_bias */

    /* 310_80 */
    node[135]->input.tensors[0] = node[133]->output.tensors[0];
    node[135]->input.tensors[1] = const_tensor[110]; /* data_weight */
    node[135]->input.tensors[2] = const_tensor[111]; /* data_bias */

    /* 320_29_321_22 */
    node[136]->input.tensors[0] = node[134]->output.tensors[0];

    /* 311_81_312_64 */
    node[137]->input.tensors[0] = node[135]->output.tensors[0];

    /* 313_63 */
    node[138]->input.tensors[0] = node[137]->output.tensors[0];
    node[138]->input.tensors[1] = const_tensor[112]; /* data_weight */
    node[138]->input.tensors[2] = const_tensor[113]; /* data_bias */

    /* 314_49_315_48 */
    node[139]->input.tensors[0] = node[138]->output.tensors[0];

    /* 316_36 */
    node[140]->input.tensors[0] = node[139]->output.tensors[0];
    node[140]->input.tensors[1] = const_tensor[114]; /* data_weight */
    node[140]->input.tensors[2] = const_tensor[115]; /* data_bias */

    /* 317_37_318_27 */
    node[141]->input.tensors[0] = node[140]->output.tensors[0];

    /* 322_21 */
    node[142]->input.tensors[0] = node[141]->output.tensors[0];
    node[142]->input.tensors[1] = node[136]->output.tensors[0];

    /* 323_15 */
    node[143]->input.tensors[0] = node[142]->output.tensors[0];
    node[143]->input.tensors[1] = const_tensor[116]; /* data_weight */
    node[143]->input.tensors[2] = const_tensor[117]; /* data_bias */

    /* 324_16_325_12 */
    node[144]->input.tensors[0] = node[143]->output.tensors[0];

    /* 622_9 */
    node[145]->input.tensors[0] = node[144]->output.tensors[0];
    node[145]->input.tensors[1] = const_tensor[118]; /* data_weight */
    node[145]->input.tensors[2] = const_tensor[119]; /* data_bias */

    /* 645_6 */
    node[146]->input.tensors[0] = node[145]->output.tensors[0];

    /* 646_3 */
    node[147]->input.tensors[0] = node[146]->output.tensors[0];


    }
    else
    {
    node[0]->output.tensors[0] = norm_tensor[0];
    node[0]->output.tensors[1] = norm_tensor[1];
    node[0]->output.tensors[2] = norm_tensor[2];
    node[0]->input.tensors[0] = norm_tensor[3];

    }
    graph->output.tensors[0] = norm_tensor[0];
    graph->output.tensors[1] = norm_tensor[1];
    graph->output.tensors[2] = norm_tensor[2];
    graph->input.tensors[0] = norm_tensor[3];


    if( enable_pre_post_process )
    {
        sort = TRUE;
        if( pre_process_map_count > 0 )
        {
            for( i = 0; i < pre_process_map_count; i++ )
            {
                status = vsi_nn_AddGraphPreProcess(graph, pre_process_map[i].graph_input_idx,
                                                   pre_process_map[i].preprocesses,
                                                   pre_process_map[i].preprocess_count);
                TEST_CHECK_STATUS( status, error );
            }
        }

        if( post_process_map_count > 0 )
        {
            for( i = 0; i < post_process_map_count; i++ )
            {
                 status = vsi_nn_AddGraphPostProcess(graph, post_process_map[i].graph_output_idx,
                                                     post_process_map[i].postprocesses,
                                                     post_process_map[i].postprocess_count);
                 TEST_CHECK_STATUS( status, error );
            }
        }
    }

    status = vsi_nn_SetupGraph( graph, sort );
    TEST_CHECK_STATUS( status, error );
    vsi_nn_DumpGraphToJson( graph );

    if( VSI_FAILURE == status )
    {
        goto error;
    }

    fclose( fp );

    return graph;

error:
    if( NULL != fp )
    {
        fclose( fp );
    }

    release_ctx = ( NULL == in_ctx );
    vsi_nn_DumpGraphToJson( graph );
    vnn_ReleaseYolov5sSimUint8( graph, release_ctx );

    return NULL;
} /* vsi_nn_CreateYolov5sSimUint8() */

void vnn_ReleaseYolov5sSimUint8
    (
    vsi_nn_graph_t * graph,
    vsi_bool release_ctx
    )
{
    vsi_nn_context_t ctx;
    if( NULL != graph )
    {
        ctx = graph->ctx;
        vsi_nn_ReleaseGraph( &graph );

        /*-----------------------------------------
        Unregister client ops
        -----------------------------------------*/
        

        if( release_ctx )
        {
            vsi_nn_ReleaseContext( &ctx );
        }
    }
} /* vsi_nn_ReleaseYolov5sSimUint8() */

